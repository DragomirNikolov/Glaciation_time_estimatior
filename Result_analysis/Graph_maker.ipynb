{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Create labels for the x-axis (temperature ranges)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "parent_dir = os.path.dirname(os.environ[\"GTE_DIR\"].replace(\"Glaciation_time_estimator\",\"\"))\n",
    "GTE_DIR=os.environ[\"GTE_DIR\"]\n",
    "sys.path.insert(0, parent_dir)\n",
    "from Glaciation_time_estimator.Auxiliary_func.config_reader import read_config\n",
    "from Glaciation_time_estimator.Data_postprocessing.Job_result_fp_generator import generate_tracking_filenames\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=read_config(os.path.join(GTE_DIR,'/config_half.yaml'))\n",
    "t_deltas = config['t_deltas']\n",
    "agg_fact = config['agg_fact']\n",
    "min_temp_array, max_temp_array = config['min_temp_arr'],config['max_temp_arr']\n",
    "folder_name=f\"{config['start_time'].strftime(config['time_folder_format'])}_{config['end_time'].strftime(config['time_folder_format'])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_cont_crit_frac=0.05"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_array_from_df(series:pd.Series):\n",
    "    if series.empty:\n",
    "        return None\n",
    "    return np.stack(series.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "start_ice_content_list=[]\n",
    "higher_final_IF_counter_temp=np.zeros(len(min_temp_array))\n",
    "labels = [f\"{min_temp_array[i]} to {max_temp_array[i]}\" for i in range( len(min_temp_array))]\n",
    "# Create a figure and two subplots side-by-side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "for i in range(len(min_temp_array)-1,-1,-1):\n",
    "    min_temp=min_temp_array[i]\n",
    "    max_temp=max_temp_array[i]\n",
    "    df=cloud_properties_df_list[i][np.where(agg_fact_list==3)[0][0]]\n",
    "    end_ice_content = Extract_array_from_df(df[\"end_ice_fraction\"][(df[\"max_ice_fraction\"]>ice_cont_crit_frac) & (df[\"track_length\"]>timedelta(minutes=60))])\n",
    "    higher_final_IF_counter_temp[i]=(start_ice_content.mean(axis=1)<end_ice_content.mean(axis=1)).sum()\n",
    "    bins=np.linspace(0,0.2,10)\n",
    "    ax1.hist(np.var(start_ice_content,axis=1),bins=bins,label=labels[i])\n",
    "    ax2.hist(np.var(start_ice_content,axis=1),bins=bins,label=labels[i])\n",
    "ax1.set_xlim(0,0.2)\n",
    "ax2.set_xlim(0,0.2)\n",
    "ax1.set_title(\"First 1h\")\n",
    "ax2.set_title(\"Last 1h\")\n",
    "ax1.set_xlabel(\"Variance\")\n",
    "ax2.set_xlabel(\"Variance\")\n",
    "ax1.set_ylabel(\"Cloud number\")\n",
    "ax2.set_ylabel(\"Cloud number\")\n",
    "fig.suptitle(\"Variance of ice concentraion at start and end of track\")\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.savefig('/cluster/work/climate/dnikolo/n2o/Glaciation_time_estimatior/Result_graphs/ice_content_variance_hist.png', dpi=400)\n",
    "higher_final_IF_counter_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels for the x-axis (temperature ranges)\n",
    "labels = [f\"{min_temp_array[i]} to {max_temp_array[i]}\" for i in range( len(min_temp_array))]\n",
    "\n",
    "# Create the bar graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, higher_final_IF_counter_temp, color='lightblue', label=\"N glaciations\")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Glaciation Occurrences Across Temperature Ranges with weak definition', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Temperature Range (Â°C)', fontsize=12)\n",
    "plt.ylabel('Glaciation Number', fontsize=12)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add gridlines for better visualization\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Format y-axis to show only integer values\n",
    "plt.gca().yaxis.get_major_locator().set_params(integer=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('/cluster/work/climate/dnikolo/n2o/Glaciation_time_estimatior/Result_graphs/glaciation_counter_temp_weak_def.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize an empty list to store the individual dataframes\n",
    "cloud_properties_df_list = []\n",
    "\n",
    "# Iterate over each temperature range\n",
    "for i in range(len(min_temp_array)):\n",
    "    cloud_properties_df_list.append([])\n",
    "    min_temp = min_temp_array[i]\n",
    "    max_temp = max_temp_array[i]\n",
    "    \n",
    "    # Iterate over each pole\n",
    "    for pole in config[\"pole_folders\"]:\n",
    "        # Construct the file path\n",
    "        fp = os.path.join(\n",
    "            config['postprocessing_output_dir'],\n",
    "            pole,\n",
    "            folder_name,\n",
    "            f\"Agg_{agg_fact:02}_T_{abs(round(min_temp)):02}_{abs(round(max_temp)):02}.parquet\"\n",
    "        )\n",
    "        \n",
    "        # Read the parquet file into a dataframe\n",
    "        df = pd.read_parquet(fp)\n",
    "        \n",
    "        # Add columns for min_temp, max_temp, and pole\n",
    "        df['min_temp'] = min_temp\n",
    "        df['max_temp'] = max_temp\n",
    "        df['pole'] = pole\n",
    "        df['Hemisphere'] = \"South\" if pole == \"sp\" else \"North\"\n",
    "        df['Lifetime [h]'] = df['track_length'] / pd.Timedelta(hours=1)\n",
    "        \n",
    "        # Append the dataframe to the sublist\n",
    "        cloud_properties_df_list[i].append(df)\n",
    "\n",
    "# Combine all dataframes into a single dataframe\n",
    "combined_df = pd.concat([df for sublist in cloud_properties_df_list for df in sublist], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_IF_hist(row):\n",
    "    lst = row['ice_frac_hist']\n",
    "    normalized_length = 100\n",
    "    original_indices = np.linspace(0, 1, len(lst))\n",
    "    target_indices = np.linspace(0, 1, normalized_length)\n",
    "    return np.interp(target_indices, original_indices, lst)\n",
    "\n",
    "def max_normalize_IF_hist(row):\n",
    "    lst = row['ice_frac_hist']\n",
    "    max_val = np.max(lst)\n",
    "    normalized_length=100\n",
    "    if max_val == 0:\n",
    "        normalized_list = np.zeros(normalized_length)\n",
    "        max_idx = None\n",
    "    else:\n",
    "        max_idx = np.argmax(lst)\n",
    "        original_indices = np.linspace(0, max_idx, len(lst[:max_idx + 1]))\n",
    "        target_indices = np.linspace(0, max_idx, normalized_length)\n",
    "        normalized_list = np.interp(target_indices, original_indices, lst[:max_idx + 1])\n",
    "        normalized_list = np.pad(normalized_list, (0, normalized_length - len(normalized_list)), constant_values=np.nan)\n",
    "    return normalized_list, max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_IF_hist_list= []\n",
    "max_norm_IF_hist_list =[]\n",
    "Timesteps_to_max_list= []\n",
    "for i, row in combined_df.iterrows():\n",
    "    if i%10000==0:\n",
    "        print(i/10000)\n",
    "    max_norm_IF_hist, Timesteps_to_max =max_normalize_IF_hist(row)\n",
    "    norm_IF_hist_list.append(normalize_IF_hist(row))\n",
    "    max_norm_IF_hist_list.append(max_norm_IF_hist)\n",
    "    Timesteps_to_max_list.append(Timesteps_to_max)\n",
    "combined_df[\"Timesteps_to_max\"] = Timesteps_to_max_list\n",
    "combined_df['max_norm_IF_hist'] = max_norm_IF_hist_list\n",
    "combined_df['norm_IF_hist'] = norm_IF_hist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Number of poles and temperature ranges\n",
    "num_poles = len(config[\"pole_folders\"])\n",
    "num_temps = len(min_temp_array)\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(num_poles, num_temps, figsize=(20, 10), sharex=True, sharey=True)\n",
    "\n",
    "# Iterate through temperature ranges and pole folders\n",
    "for t_ind in range(num_temps):\n",
    "    for pole_ind in range(num_poles):\n",
    "        ax = axes[pole_ind, t_ind]  # Select the appropriate subplot\n",
    "        df = cloud_properties_df_list[t_ind][pole_ind]\n",
    "        min_temp = min_temp_array[t_ind]\n",
    "        max_temp = max_temp_array[t_ind]\n",
    "\n",
    "        # Plot histogram\n",
    "        sns.histplot(\n",
    "            x=df[\"avg_size[km]\"], \n",
    "            bins=10, \n",
    "            kde=True, \n",
    "            log_scale=[True, False], \n",
    "            color='skyblue', \n",
    "            edgecolor='black', \n",
    "            linewidth=0.8, \n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # Set title for each subplot\n",
    "        hemisphere= \"Southern hemisphere\" if pole_ind == 1  else  \"Northern hemisphere\"\n",
    "        ax.set_title(f\"T: {min_temp}\\u00B0 to {max_temp}\\u00B0\", fontsize=10)\n",
    "\n",
    "        # Customize x-axis and y-axis labels\n",
    "        if pole_ind == num_poles - 1:  # Bottom row\n",
    "            ax.set_xlabel(\"Time-Averaged Cloud Area [kmÂ²]\", fontsize=8)\n",
    "        if t_ind == 0:  # First column\n",
    "            ax.set_ylabel(\"Number of Clouds\", fontsize=8)\n",
    "\n",
    "        # Set x-axis scale and grid\n",
    "        ax.set_xlim(1e3, 1e6)\n",
    "        ax.set_xscale('log')\n",
    "        ax.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "        \n",
    "        # Customize ticks\n",
    "        ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "\n",
    "fig.text(0.5, 0.95, \"Northern Hemisphere\", ha='center', va='center', fontsize=14, weight='bold')\n",
    "fig.text(0.5, 0.50, \"Southern Hemisphere\", ha='center', va='center', fontsize=14, weight='bold')\n",
    "\n",
    "# Adjust layout\n",
    "# fig.tight_layout(rect=[0, 0, 1, 0.92]) \n",
    "# plt.subplots_adjust(top=0.9, hspace=0.4)  # Increase top margin and spacing between rows\n",
    "# Adjust layout to avoid overlapping\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "filename=os.path.join(GTE_DIR,\"/Result_graphs/size_hist_temp_subplots\")\n",
    "plt.savefig(filename+'.png', dpi=400)\n",
    "plt.savefig(filename+'.pdf', dpi=400)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=combined_df, x=\"avg_size[km]\",hue='Hemisphere',bins=20, kde=True, log_scale=[True, False], color='skyblue', edgecolor='black', linewidth=0.8)\n",
    "# plt.legend(title='Hemisphere', loc='upper right', labels=['North', 'South'])\n",
    "# Labels and title\n",
    "plt.xlabel(\"Time-Averaged Cloud Area [kmÂ²]\", fontsize=12)\n",
    "plt.ylabel(\"Number of Clouds\", fontsize=12)\n",
    "plt.title(\"Histogram of Cloud Area between\", fontsize=14, fontweight='bold')\n",
    "\n",
    "# Customize x-axis\n",
    "plt.xlim(1e3, 1e6)\n",
    "plt.xscale('log')\n",
    "plt.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Ticks\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Save the figure\n",
    "plt.tight_layout()  # Adjust layout to avoid clipping\n",
    "# plt.savefig(os.path.join(GTE_DIR,'/Result_graphs/size_hist_T_5_0_np.png', dpi=400)\n",
    "filename=os.path.join(GTE_DIR,\"/Result_graphs/size_hist_by_pole\")\n",
    "plt.savefig(filename+'.png', dpi=400)\n",
    "plt.savefig(filename+'.pdf', dpi=400)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=combined_df, x=\"Lifetime [h]\",hue='Hemisphere',binwidth=1, color='skyblue',log_scale=[False, True], edgecolor='black', linewidth=0.8)\n",
    "# plt.legend(title='Hemisphere', loc='upper right', labels=['North', 'South'])\n",
    "# Labels and title\n",
    "plt.xlabel(\"Tracking lifetime [h]\", fontsize=12)\n",
    "plt.ylabel(\"Number of Clouds\", fontsize=12)\n",
    "plt.title(\"Histogram of Cloud Lifetimes\", fontsize=14, fontweight='bold')\n",
    "\n",
    "# Customize x-axis\n",
    "# plt.xlim(1e3, 1e6)\n",
    "plt.yscale('log')\n",
    "plt.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Ticks\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlim(left=0, right=60)\n",
    "# Save the figure\n",
    "plt.tight_layout()  # Adjust layout to avoid clipping\n",
    "# plt.savefig(os.path.join(GTE_DIR,'/Result_graphs/size_hist_T_5_0_np.png', dpi=400)\n",
    "filename=os.path.join(GTE_DIR,\"/Result_graphs/lifetime_hist_by_pole\")\n",
    "plt.savefig(filename+'.png', dpi=400)\n",
    "plt.savefig(filename+'.pdf', dpi=400)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cloud(row, params):\n",
    "    norm_ice_frac_hist = row['norm_IF_hist']\n",
    "    if (max(norm_ice_frac_hist) >=params['crit_max_IF']) and row['Timesteps_to_max'] >=params['min_time_to_max'] and row['track_length']>=params['crit_lifetime'] and (max(norm_ice_frac_hist) >= norm_ice_frac_hist[:10].mean()+params['min_delta_IF']):\n",
    "        return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "crit_max_IF_vals = np.arange(0.1,0.91,0.2)\n",
    "crit_lifetime_vals = [timedelta(minutes=45), timedelta(hours=1), timedelta(hours=2) ,timedelta(hours=3)]\n",
    "min_delta_IF_vals = [-1,0,0.3,0.6,0.9]\n",
    "min_time_to_max_vals = [0,4,8]\n",
    "print(crit_max_IF_vals, crit_lifetime_vals, min_delta_IF_vals)\n",
    "\n",
    "all_combinations = product(crit_max_IF_vals, crit_lifetime_vals, min_delta_IF_vals, min_time_to_max_vals)\n",
    "\n",
    "# Create a dataframe\n",
    "params_df = pd.DataFrame(all_combinations, columns=['crit_max_IF', 'crit_lifetime', 'min_delta_IF', 'min_time_to_max'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_param_comb(params_row):\n",
    "    # print(f\"It\")\n",
    "    # check_params = {\n",
    "    #     'crit_max_IF': row[\"crit_max_IF\"],\n",
    "    #     'crit_lifetime': row[\"crit_lifetime\"],\n",
    "    #     'min_delta_IF': row[\"min_delta_IF\"],\n",
    "    #     'min_time_to_max': row[\"min_time_to_max\"]}\n",
    "    part_check_cloud = partial(check_cloud, params=params_row)\n",
    "    combined_df['Filter_check'] = combined_df.apply(part_check_cloud, axis=1)\n",
    "    return combined_df['Filter_check'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(8) as pool:\n",
    "    n_passing_clouds = pool.map(check_param_comb, [row for _, row in params_df.iterrows()])\n",
    "\n",
    "# Assigning results back to `params_df`\n",
    "params_df['N_passing_clouds'] = n_passing_clouds\n",
    "\n",
    "print(params_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairs of variables for axes\n",
    "params_df[\"Min Lifetime [h]\"] = params_df[\"crit_lifetime\"]/ timedelta(hours=1)\n",
    "params_df['Frac passing clouds'] = params_df[\"N_passing_clouds\"]/len(combined_df) *100\n",
    "params_df[\"crit_max_IF\"] = round(params_df[\"crit_max_IF\"],2)\n",
    "params_df[\"min_time_to_max [h]\"] = params_df[\"min_time_to_max\"]/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params_df[\"x_pair\"] = params_df[\"crit_max_IF\"].astype(str) + \", \" + params_df[\"Min Lifetime [h]\"].astype(str)\n",
    "params_df[\"y_pair\"] = params_df[\"min_delta_IF\"].astype(str) + \", \" + params_df[\"min_time_to_max [h]\"].astype(str)\n",
    "\n",
    "# Pivot table for heatmap\n",
    "heatmap_data = params_df.pivot_table(\n",
    "    index=\"y_pair\",\n",
    "    columns=\"x_pair\",\n",
    "    values=\"Frac passing clouds\",\n",
    "    aggfunc=\"mean\"\n",
    ")\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\".01f\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Percentage fraction of filter passing clouds\")\n",
    "plt.xlabel(\"Max IF Theshold, Min Lifetime\")\n",
    "plt.ylabel(\"Min ÎIF from start , Min time to max IF\")\n",
    "filename=os.path.join(GTE_DIR,\"/Result_graphs/frac_filter_passing_clouds\")\n",
    "plt.savefig(filename+'.png', dpi=400)\n",
    "plt.savefig(filename+'.pdf', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=combined_df, x= \"avg_size[km]\", y = \"Lifetime [h]\")\n",
    "plt.xscale('log')\n",
    "plt.ylim(0,60)\n",
    "plt.xlim(1e3,1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = combined_df[[\"avg_size[km]\", \"Lifetime [h]\", \"min_temp\",\"Timesteps_to_max\"]]\n",
    "sns.PairGrid(data=clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'clean_df' is the DataFrame containing the columns\n",
    "pairplot = sns.pairplot(clean_df, hue=\"min_temp\", plot_kws={'alpha': 0.7})\n",
    "\n",
    "# Apply a logarithmic scale to the x-axis of the \"avg_size[km]\" variable\n",
    "for ax in pairplot.axes.flatten():\n",
    "    # Apply log scale to 'avg_size[km]' on the x-axis\n",
    "    if ax.get_xlabel() == 'avg_size[km]':\n",
    "        ax.set_xscale('log')\n",
    "\n",
    "# Get indices of the diagonal axes\n",
    "# diagonal_indices = np.diag_indices_from(pairplot.axes)\n",
    "\n",
    "# # Apply log scale to the y-axis of the diagonal plots (Lifetime [h] vs Lifetime [h], Timesteps_to_max vs Timesteps_to_max)\n",
    "# for i, j in zip(*diagonal_indices):\n",
    "#     ax = pairplot.axes[i, j]\n",
    "#     ax.set_yscale('log')\n",
    "filename=os.path.join(GTE_DIR,\"/Result_graphs/pairplot_all\")\n",
    "plt.savefig(filename+'.png', dpi=400)\n",
    "plt.savefig(filename+'.pdf', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = combined_df[[\"avg_size[km]\", \"Lifetime [h]\", \"min_temp\", \"Timesteps_to_max\", \"max_ice_fraction\", \"avg_lat\"]].sample(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = clean_df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "# sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "#             square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, center=0, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset\n",
    "\n",
    "\n",
    "# Create the PairGrid\n",
    "g = sns.PairGrid(clean_df)\n",
    "\n",
    "# Define how to plot each subplot\n",
    "g.map_upper(sns.scatterplot)  # Scatter plot for the upper triangle\n",
    "g.map_lower(sns.scatterplot)  # Scatter plot for the lower triangle\n",
    "g.map_diag(sns.histplot, kde=True)  # Histogram with KDE for the diagonal\n",
    "\n",
    "# Replace subplots with `min_temp` as one of the axes with box plots\n",
    "for i, var_i in enumerate(g.x_vars):\n",
    "    for j, var_j in enumerate(g.y_vars):\n",
    "        if var_i == \"min_temp\": #or var_j == \"min_temp\":\n",
    "            if i != j:  # Avoid diagonal plots\n",
    "                ax = g.axes[j, i]  # Get the corresponding axes\n",
    "                sns.boxplot(x=clean_df[var_i], y=clean_df[var_j], ax=ax)\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_filter(row):\n",
    "    IF = np.array(row['norm_IF_hist'])\n",
    "    if IF[:50].mean() + 0.1 < IF[50:].mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_filter(combined_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(combined_df['is_liq']& combined_df['is_mix'] & combined_df['is_ice']).astype(bool).sum(axis=0)/len(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = combined_df[[\"avg_size[km]\", \"Lifetime [h]\", \"min_temp\",\"Timesteps_to_max\"]]\n",
    "sns.pairplot(data=clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta(minutes=45)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
