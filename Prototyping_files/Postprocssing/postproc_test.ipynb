{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import numba as nb\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import os\n",
    "from multiprocessing import Manager\n",
    "import sys\n",
    "sys.path.insert(0,'/cluster/work/climate/dnikolo/n2o')\n",
    "from Glaciation_time_estimator.Auxiliary_func.config_reader import read_config\n",
    "# from Glaciation_time_estimator.Data_postprocessing.Single_cloud_analysis import Cloud\n",
    "from Glaciation_time_estimator.Data_postprocessing.Job_result_fp_generator import generate_tracking_filenames\n",
    "from Glaciation_time_estimator.Auxiliary_func.Nestable_multiprocessing import NestablePool\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit\n",
    "def extract_cloud_coordinates(cloudtracknumber_field, cloud_id_in_field, max_size):\n",
    "    # Define the dictionary with the appropriate types\n",
    "    loc_hash_map_cloud_numbers = {\n",
    "        j: (0, np.zeros((2, max_size), dtype=np.int16)) for j in cloud_id_in_field}\n",
    "    # # Traverse the 3D array\n",
    "    # for i in cloud_id_in_field:\n",
    "    #     loc_hash_map_cloud_numbers[val] = (0,np.empty((2,max_size),dtype=np.int16))\n",
    "    for row in range(cloudtracknumber_field.shape[1]):\n",
    "        for col in range(cloudtracknumber_field.shape[2]):\n",
    "            val = cloudtracknumber_field[0, row, col]\n",
    "            if val != 0:\n",
    "                ind, cord = loc_hash_map_cloud_numbers[val]\n",
    "                if ind <= max_size:\n",
    "                    cord[:, ind] = np.asarray([row, col], dtype=np.int16)\n",
    "                    ind += 1\n",
    "                    # print(ind)\n",
    "                    loc_hash_map_cloud_numbers[val] = (ind, cord)\n",
    "    return loc_hash_map_cloud_numbers\n",
    "    # return loc_hash_map_cloud_numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a= np.array([None,None,None])\n",
    "# b= np.array([1,1,1])\n",
    "# cpp_data = xr.load_dataset(\"/cluster/work/climate/dnikolo/dump/Data/np/CPPin20210101000000405SVMSGI1MD.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cot_values = cpp_data[\"cot\"].values[0,[2,3,4],[4,5,6]]\n",
    "# # ctp_data = np.array([1,2,np.nan])\n",
    "# print(ctp_data)\n",
    "# pixel_area = np.arange(3)\n",
    "# np.average(cot_values,weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.count_nonzero(np.isnan(cot_values))/cot_values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cot_values = cpp_data[\"cot\"].values[0,[2,3,4],[4,5,6]]\n",
    "# invalid_area_frac = np.count_nonzero(pixel_area>66)/pixel_area.shape[0]\n",
    "# no_cot_frac = np.count_nonzero(np.isnan(cot_values))/cot_values.shape[0]\n",
    "# weights = pixel_area[~np.isnan(cot_values)]\n",
    "# cot_values = cot_values[~np.isnan(cot_values)]\n",
    "# np.average(cot_values,weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CoordinateTransformer:\n",
    "    def __init__(self, target_shape, agg_fact):\n",
    "        self.agg_fact = agg_fact\n",
    "        self.target_shape=target_shape\n",
    "\n",
    "    def transform(self, lat_ind, lon_ind):\n",
    "        transformed_lat_ind = np.empty((len(lat_ind)*self.agg_fact**2), dtype=int)\n",
    "        transformed_lon_ind = np.empty((len(lon_ind)*self.agg_fact**2), dtype=int)\n",
    "        step = self.agg_fact**2\n",
    "        for k in range(step):\n",
    "            i=k//self.agg_fact\n",
    "            j=k%self.agg_fact\n",
    "            transformed_lat_ind[k::step] = lat_ind*self.agg_fact+i\n",
    "            transformed_lon_ind[k::step] = lon_ind*self.agg_fact+j\n",
    "        mask = (transformed_lat_ind < self.target_shape[0]) & (transformed_lon_ind < self.target_shape[1]) \n",
    "        # print(mask)\n",
    "        transformed_lon_ind = transformed_lon_ind[mask]\n",
    "        transformed_lat_ind = transformed_lat_ind[mask]\n",
    "        return transformed_lat_ind.T, transformed_lon_ind.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "\n",
    "class Cloud:\n",
    "    # def __new__(self, *args, **kwargs):\n",
    "    #     return super().__new__(self)\n",
    "    def __init__(self, cloud_id, is_resampled):\n",
    "        self.id = cloud_id\n",
    "        self.is_resampled = is_resampled\n",
    "        self.crit_fraction = 0.1\n",
    "        # Bools inidicating if the cloud has been liquid at any point\n",
    "        self.is_liq: bool = False\n",
    "        self.is_mix: bool = False\n",
    "        self.is_ice: bool = False\n",
    "        # Max and min cloud size in pixels\n",
    "        self.max_size_km: float = 0.0\n",
    "        self.max_size_px: int = 0\n",
    "        self.min_size_km: float = 510.0e6\n",
    "        self.min_size_px: int = 3717*3717\n",
    "\n",
    "        # Variables giving the first and last 4 timesteps (1 hour) of the cloud ice fraction - both arrays run in the same time direction start: [1 , 2 , 3 , 4] ... end: [1 , 2 , 3 , 4]\n",
    "        self.start_ice_fraction_arr = np.empty(4)\n",
    "        self.end_ice_fraction_arr = np.empty(4)\n",
    "        # self.ice_fraction_arr=np.empty(max_timesteps)\n",
    "        self.ice_fraction_list = []\n",
    "        \n",
    "\n",
    "        self.max_water_fraction: float = 0.0\n",
    "        self.max_ice_fraction: float = 0.0\n",
    "\n",
    "        self.track_start_time: dt.datetime = None\n",
    "        self.track_end_time: dt.datetime = None\n",
    "        self.track_length = None\n",
    "\n",
    "        self.glaciation_start_time: dt.datetime = None\n",
    "        self.glaciation_end_time: dt.datetime = None\n",
    "\n",
    "        self.n_timesteps = None\n",
    "\n",
    "        self.sum_cloud_cot=0\n",
    "        self.avg_cot = None\n",
    "        self.cot_timestep_counter=0\n",
    "        self.mean_cot_list = []\n",
    "        self.std_cot_list = []\n",
    "\n",
    "        self.sum_cloud_ctp=0\n",
    "        self.avg_ctp = None\n",
    "        self.ctp_timestep_counter=0\n",
    "        self.mean_ctp_list = []\n",
    "        self.std_ctp_list = []\n",
    "\n",
    "        self.sum_cloud_cwp=0\n",
    "        self.avg_cwp = None\n",
    "        self.cwp_timestep_counter=0\n",
    "        self.mean_cwp_list = []\n",
    "        self.std_cwp_list = []\n",
    "        \n",
    "        self.sum_cloud_lat = 0.0\n",
    "        self.sum_cloud_lon = 0.0\n",
    "        self.avg_cloud_lat = None\n",
    "        self.avg_cloud_lon = None\n",
    "        self.lon_list=[]\n",
    "        self.lat_list=[]\n",
    "\n",
    "        self.sum_cloud_size_km = 0.0\n",
    "        self.avg_cloud_size_km = None\n",
    "        self.cloud_size_km_list = []\n",
    "        self.large_pixel_cloud=False\n",
    "\n",
    "        self.sum_cloud_size_px = 0.0\n",
    "        self.avg_cloud_size_px = None\n",
    "\n",
    "        \n",
    "        self.valid_cot_cloud = False\n",
    "        self.cot_nan_frac_list=[]\n",
    "\n",
    "        self.valid_ctp_cloud = False\n",
    "        self.ctp_nan_frac_list=[]\n",
    "\n",
    "        self.n_timesteps_no_cloud = 0\n",
    "        self.terminate_cloud = False\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.is_liq},{self.is_mix},{self.is_ice},\"\n",
    "    #In resampled clouds pixel area should be the area in degrees lon_resolution*lat_resolution\n",
    "    def update_status(self, time: dt.datetime, cloud_values: np.array, cot_values, ctp_values, cloud_lat, cloud_lon ,pixel_area):\n",
    "        ind_to_take = ~np.isnan(pixel_area)\n",
    "        pixel_area = pixel_area[ind_to_take]\n",
    "        cot_values = cot_values[ind_to_take]\n",
    "        ctp_values = ctp_values[ind_to_take]\n",
    "        cloud_lat = cloud_lat[ind_to_take]\n",
    "        cloud_lon = cloud_lon[ind_to_take]\n",
    "        cloud_size_px = cloud_values.shape[0]\n",
    "        if not self.is_resampled:\n",
    "            cloud_lat = np.average(cloud_lat,weights=pixel_area)\n",
    "            cloud_lon = np.average(cloud_lon,weights=pixel_area)\n",
    "            # cloud_lat = 10\n",
    "            # cloud_lon = 10\n",
    "        # print(cloud_values)\n",
    "        if cloud_size_px:\n",
    "            self.n_timesteps_no_cloud = 0\n",
    "            valid_values = cloud_values[cloud_values >= 1]\n",
    "            # print(len(valid_values)/len(cloud_values))\n",
    "            ice_fraction = (valid_values.sum() -\n",
    "                            float(len(valid_values)))/float(len(valid_values))\n",
    "            # print(valid_values)\n",
    "            # ice_fraction=float(np.count_nonzero(cloud_values==2))/float(cloud_size_px)\n",
    "            water_fraction = 1-ice_fraction\n",
    "            # assert math.isclose(water_fraction+ice_fraction,1)\n",
    "            # print(water_fraction)\n",
    "            # print(water_fraction)f cloud_arr[track_number-1] is None:\n",
    "            \n",
    "            if not (self.track_start_time):\n",
    "                self.track_start_time = time\n",
    "                self.n_timesteps = 1\n",
    "            else:\n",
    "                self.n_timesteps += 1\n",
    "            if self.n_timesteps <= 4:\n",
    "                self.start_ice_fraction_arr[self.n_timesteps-1] = ice_fraction\n",
    "            # Check and set type of cloud\n",
    "            if water_fraction > 1-self.crit_fraction:\n",
    "                self.is_liq = True\n",
    "            elif water_fraction > self.crit_fraction:\n",
    "                self.is_mix = True\n",
    "            else:\n",
    "                self.is_ice = True\n",
    "            if self.is_resampled:\n",
    "                cloud_size_km = pixel_area*cloud_size_px * \\\n",
    "                    np.cos(np.deg2rad(cloud_lat))*111.321*111.111\n",
    "            else:\n",
    "                cloud_size_km = pixel_area.sum()\n",
    "                large_pixel_frac = np.count_nonzero(pixel_area>66)/pixel_area.shape[0]\n",
    "                if large_pixel_frac>0.1 or pixel_area.max()>110:\n",
    "                    self.large_pixel_cloud = True\n",
    "            self.cloud_size_km_list.append(cloud_size_km)\n",
    "            self.max_size_km = max(self.max_size_km, cloud_size_km)\n",
    "            self.min_size_km = min(self.min_size_km, cloud_size_km)\n",
    "\n",
    "            self.max_size_px = max(self.max_size_px, cloud_size_px)\n",
    "            self.min_size_px = min(self.min_size_px, cloud_size_px)\n",
    "\n",
    "            self.sum_cloud_size_px += cloud_size_px\n",
    "            self.avg_cloud_size_px = self.sum_cloud_size_px/self.n_timesteps\n",
    "\n",
    "            self.sum_cloud_size_km += cloud_size_km\n",
    "            self.avg_cloud_size_km = self.sum_cloud_size_km/self.n_timesteps\n",
    "\n",
    "            # I assume that water_frac+ice_frac=1\n",
    "\n",
    "            self.max_water_fraction = max(\n",
    "                self.max_water_fraction, water_fraction)\n",
    "            self.max_ice_fraction = max(\n",
    "                self.max_ice_fraction, 1-water_fraction)\n",
    "\n",
    "            self.sum_cloud_lat += cloud_lat\n",
    "            self.sum_cloud_lon += cloud_lon\n",
    "            self.lon_list.append(cloud_lon)\n",
    "            self.lat_list.append(cloud_lat)\n",
    "            self.avg_cloud_lat = self.sum_cloud_lat/self.n_timesteps\n",
    "            self.avg_cloud_lon = self.sum_cloud_lon/self.n_timesteps\n",
    "\n",
    "            self.track_end_time = time\n",
    "            self.track_length = self.track_end_time-self.track_start_time\n",
    "\n",
    "            self.end_ice_fraction_arr[0:3] = self.end_ice_fraction_arr[1:4]\n",
    "            self.end_ice_fraction_arr[3] = ice_fraction\n",
    "\n",
    "            # self.ice_fraction_arr[n_timesteps]=ice_fraction\n",
    "            self.ice_fraction_list.append(ice_fraction)\n",
    "\n",
    "            self.update_cot_variables(cot_values,pixel_area)\n",
    "            self.update_ctp_variables(ctp_values,pixel_area)\n",
    "            \n",
    "    def update_cot_variables(self,cot_values,pixel_area):\n",
    "        cot_nan_frac = np.count_nonzero(np.isnan(cot_values))/cot_values.shape[0]\n",
    "        if cot_nan_frac>0.1:\n",
    "            self.valid_cot_cloud=False\n",
    "        self.cot_nan_frac_list.append(cot_nan_frac)\n",
    "        weights = pixel_area[~np.isnan(cot_values)]\n",
    "        if len(weights)>0:\n",
    "            cot_values = cot_values[~np.isnan(cot_values)]\n",
    "            mean_cot = np.average(cot_values,weights=weights)\n",
    "            if cot_nan_frac<0.1:\n",
    "                self.sum_cloud_cot+=mean_cot\n",
    "                self.cot_timestep_counter+=1\n",
    "                self.avg_cot=self.sum_cloud_cot/self.cot_timestep_counter\n",
    "        else:\n",
    "            mean_cot = np.nan\n",
    "        self.mean_cot_list.append(mean_cot)\n",
    "\n",
    "    def update_ctp_variables(self, ctp_values,pixel_area):\n",
    "        ctp_nan_frac = np.count_nonzero(np.isnan(ctp_values))/ctp_values.shape[0]\n",
    "        if ctp_nan_frac>0.1:\n",
    "            self.valid_ctp_cloud=False\n",
    "        self.ctp_nan_frac_list.append(ctp_nan_frac)\n",
    "        weights = pixel_area[~np.isnan(ctp_values)]\n",
    "        if len(weights)>0:\n",
    "            ctp_values = ctp_values[~np.isnan(ctp_values)]\n",
    "            mean_ctp = np.average(ctp_values,weights=weights)\n",
    "            if ctp_nan_frac<0.1:\n",
    "                self.sum_cloud_ctp+=mean_ctp\n",
    "                self.ctp_timestep_counter+=1\n",
    "                self.avg_ctp=self.sum_cloud_ctp/self.ctp_timestep_counter\n",
    "        else:\n",
    "            mean_ctp = np.nan\n",
    "        self.mean_ctp_list.append(mean_ctp)\n",
    "\n",
    "    def update_missing_cloud(self):\n",
    "        if self.track_end_time and (not self.terminate_cloud):\n",
    "            self.n_timesteps_no_cloud += 1\n",
    "            if self.n_timesteps_no_cloud > 1:\n",
    "                self.terminate_cloud = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Glaciation_time_estimator.Data_postprocessing.Single_cloud_analysis import Cloud\n",
    "# from Glaciation_time_estimator.Data_postprocessing.Job_result_fp_generator import generate_tracking_filenames\n",
    "# from multiprocessing import Manager\n",
    "# from Glaciation_time_estimator.Auxiliary_func.Nestable_multiprocessing import NestablePool\n",
    "# from functools import partial\n",
    "# import os\n",
    "\n",
    "\n",
    "@nb.njit\n",
    "def extract_cloud_coordinates(cloudtracknumber_field, cloud_id_in_field, max_size):\n",
    "    # Define the dictionary with the appropriate types\n",
    "    loc_hash_map_cloud_numbers = {\n",
    "        j: (0, np.zeros((2, max_size), dtype=np.int16)) for j in cloud_id_in_field}\n",
    "    # # Traverse the 3D array\n",
    "    # for i in cloud_id_in_field:\n",
    "    #     loc_hash_map_cloud_numbers[val] = (0,np.empty((2,max_size),dtype=np.int16))\n",
    "    for row in range(cloudtracknumber_field.shape[1]):\n",
    "        for col in range(cloudtracknumber_field.shape[2]):\n",
    "            val = cloudtracknumber_field[0, row, col]\n",
    "            if val != 0:\n",
    "                ind, cord = loc_hash_map_cloud_numbers[val]\n",
    "                if ind <= max_size:\n",
    "                    cord[:, ind] = np.asarray([row, col], dtype=np.int16)\n",
    "                    ind += 1\n",
    "                    # print(ind)\n",
    "                    loc_hash_map_cloud_numbers[val] = (ind, cord)\n",
    "    return loc_hash_map_cloud_numbers\n",
    "    # return loc_hash_map_cloud_numbers\n",
    "\n",
    "\n",
    "class CoordinateTransformer:\n",
    "    def __init__(self, target_shape, agg_fact):\n",
    "        self.agg_fact = agg_fact\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def transform(self, lat_ind, lon_ind):\n",
    "        transformed_lat_ind = np.empty(\n",
    "            (len(lat_ind)*self.agg_fact**2), dtype=int)\n",
    "        transformed_lon_ind = np.empty(\n",
    "            (len(lon_ind)*self.agg_fact**2), dtype=int)\n",
    "        step = self.agg_fact**2\n",
    "        for k in range(step):\n",
    "            i = k//self.agg_fact\n",
    "            j = k % self.agg_fact\n",
    "            transformed_lat_ind[k::step] = lat_ind*self.agg_fact+i\n",
    "            transformed_lon_ind[k::step] = lon_ind*self.agg_fact+j\n",
    "        mask = (transformed_lat_ind < self.target_shape[0]) & (\n",
    "            transformed_lon_ind < self.target_shape[1])\n",
    "        # print(mask)\n",
    "        transformed_lon_ind = transformed_lon_ind[mask]\n",
    "        transformed_lat_ind = transformed_lat_ind[mask]\n",
    "        return transformed_lat_ind.T, transformed_lon_ind.T\n",
    "\n",
    "\n",
    "def extract_value(val):\n",
    "    if isinstance(val, xr.DataArray):\n",
    "        return val.values.item() if val.size == 1 else val.values\n",
    "    return val\n",
    "\n",
    "\n",
    "def extract_cpp_vars(time, pole):\n",
    "    cpp_filename = time.strftime(\"CPPin%Y%m%d%H%M%S405SVMSGI1MD.nc\")\n",
    "    with xr.load_dataset(os.path.join(os.environ[\"TMPDIR\"], \"Data\", pole, cpp_filename)) as cpp_data:\n",
    "        return cpp_data['cot'],cpp_data['cwp']\n",
    "\n",
    "def extract_ctx_vars(time, pole):\n",
    "    ctx_filename = time.strftime(\"CTXin%Y%m%d%H%M%S405SVMSGI1MD.nc\")\n",
    "    with xr.load_dataset(os.path.join(os.environ[\"TMPDIR\"], \"Data\", pole, ctx_filename)) as ctx_data:\n",
    "        return ctx_data['ctp']\n",
    "    # print(f'{min_temp} to {max_temp} Loading {time_str}')\n",
    "# /cluster/work/climate/dnikolo/dump/Data/np/CPPin20210101000000405SVMSGI1MD.nc\n",
    "\n",
    "\n",
    "def extract_cloud_number_field(cloudtrack_data):\n",
    "    cloudtracknumber_field = cloudtrack_data['tracknumber'].data\n",
    "    cloudtracknumber_field[np.isnan(cloudtracknumber_field)] = 0\n",
    "    return cloudtracknumber_field.astype(int)\n",
    "\n",
    "\n",
    "def save_single_temp_range_results(cloud_arr, pole, min_temp, max_temp, config):\n",
    "    columns = [\"is_large_pix_cloud\", \"is_cot_valid_cloud\",\"is_ctp_valid_cloud\", \"is_liq\", \"is_mix\", \"is_ice\", \"max_water_frac\",\n",
    "               \"max_ice_fraction\", \"avg_size[km]\", \"max_size[km]\",\n",
    "               \"min_size[km]\", \"avg_size[px]\", \"max_size[px]\",\n",
    "               \"min_size[px]\", \"track_start_time\", \"track_length\", \"avg_cot\",\"avg_ctp\",\n",
    "               \"glaciation_start_time\", \"glaciation_end_time\", \"avg_lat\",\n",
    "               \"avg_lon\", \"start_ice_fraction\", \"end_ice_fraction\",\n",
    "               \"ice_frac_hist\", \"cot_hist\", \"cot_nan_frac_hist\",\"ctp_hist\", \"ctp_nan_frac_hist\", \"lat_hist\", \"lon_hist\",\n",
    "               \"size_hist_km\"]\n",
    "    datapoints_per_cloud = len(columns)\n",
    "    cloudinfo_df = pd.DataFrame(\n",
    "        index=range(len(cloud_arr)), columns=columns)\n",
    "    for cloud_ind in range(len(cloud_arr)):\n",
    "        current_cloud = cloud_arr[cloud_ind]\n",
    "        if current_cloud is not None:\n",
    "            cloudinfo_df.iloc[cloud_ind] = [\n",
    "                current_cloud.large_pixel_cloud,\n",
    "                current_cloud.valid_cot_cloud,\n",
    "                current_cloud.valid_ctp_cloud,\n",
    "                current_cloud.is_liq,\n",
    "                current_cloud.is_mix,\n",
    "                current_cloud.is_ice,\n",
    "                current_cloud.max_water_fraction,\n",
    "                current_cloud.max_ice_fraction,\n",
    "                extract_value(current_cloud.avg_cloud_size_km),\n",
    "                extract_value(current_cloud.max_size_km),\n",
    "                extract_value(current_cloud.min_size_km),\n",
    "                extract_value(current_cloud.avg_cloud_size_px),\n",
    "                extract_value(current_cloud.max_size_px),\n",
    "                extract_value(current_cloud.min_size_px),\n",
    "                current_cloud.track_start_time,\n",
    "                current_cloud.track_length,\n",
    "                current_cloud.avg_cot,\n",
    "                current_cloud.avg_ctp,\n",
    "                current_cloud.glaciation_start_time,\n",
    "                current_cloud.glaciation_end_time,\n",
    "                extract_value(current_cloud.avg_cloud_lat),\n",
    "                extract_value(current_cloud.avg_cloud_lon),\n",
    "                current_cloud.start_ice_fraction_arr,\n",
    "                current_cloud.end_ice_fraction_arr,\n",
    "                current_cloud.ice_fraction_list,\n",
    "                current_cloud.mean_cot_list,\n",
    "                current_cloud.cot_nan_frac_list,\n",
    "                current_cloud.mean_ctp_list,\n",
    "                current_cloud.ctp_nan_frac_list,\n",
    "                current_cloud.lat_list,\n",
    "                current_cloud.lon_list,\n",
    "                current_cloud.cloud_size_km_list\n",
    "            ]\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    output_dir = os.path.join(\n",
    "        config['postprocessing_output_dir'], pole,\n",
    "        config['time_folder_name'],\n",
    "        f\"Agg_{config['agg_fact']:02}_T_{abs(round(min_temp)):02}_{abs(round(max_temp)):02}\"\n",
    "    )\n",
    "    os.makedirs(os.path.dirname(output_dir), exist_ok=True)\n",
    "\n",
    "    # Save DataFrame to Parquet\n",
    "    output_dir_parq = output_dir + \".parquet\"\n",
    "    print(\"Writing to \", output_dir_parq)\n",
    "    cloudinfo_df.to_parquet(output_dir_parq)\n",
    "\n",
    "    # Optionally save as CSV\n",
    "    if config['write_csv']:\n",
    "        output_dir_csv = output_dir + \".csv\"\n",
    "        cloudinfo_df.to_csv(output_dir_csv)\n",
    "\n",
    "\n",
    "def analize_single_temp_range(temp_ind: int, cloud_dict, tracking_fps: dict, pole: str, config: dict, pix_area=None,  lon=None, lat=None) -> None:\n",
    "    # loop_start_time=dt.datetime.now()\n",
    "    min_temp, max_temp = config['min_temp_arr'][temp_ind], config['max_temp_arr'][temp_ind]\n",
    "    is_resampled = config[\"Resample\"]\n",
    "    collect_cot = config[\"collect_additional_properties\"]\n",
    "    # Load datasets\n",
    "    temp_key = f'{abs(round(min_temp))}_{abs(round(max_temp))}'\n",
    "    print(f\"Analyzing {pole} {temp_key}\")\n",
    "    # print(tracking_fps[pole][temp_key][\"cloudtracks\"][0])\n",
    "    # print(tracking_fps[pole][temp_key][\"trackstats_final\"])\n",
    "    # print(tracking_fps[pole][temp_key][\"tracknumbers\"])\n",
    "    try:\n",
    "        # print(tracking_fps[pole][temp_key][\"cloudtracks\"][0])\n",
    "        cloudtrack_data = xr.load_dataset(\n",
    "            tracking_fps[pole][temp_key][\"cloudtracks\"][0])\n",
    "        trackstats_data = xr.load_dataset(\n",
    "            tracking_fps[pole][temp_key][\"trackstats_final\"])\n",
    "        tracknumbers_data = xr.load_dataset(\n",
    "            tracking_fps[pole][temp_key][\"tracknumbers\"])\n",
    "    except:  # Exception as inst:\n",
    "        print(f\"Skipping {pole} {min_temp} to {max_temp}\")\n",
    "        cloud_dict[temp_key] = np.array([])\n",
    "        return None\n",
    "    # Load relevant data from datasets into local variables\n",
    "    n_tracks = trackstats_data.variables['track_duration'].shape[0]\n",
    "    basetimes = pd.to_datetime(tracknumbers_data['basetimes'])\n",
    "    if is_resampled:\n",
    "        lat = cloudtrack_data['lat']\n",
    "        lon = cloudtrack_data['lon']\n",
    "        lat_resolution = (lat.max()-lat.min())/len(lat)\n",
    "        lon_resolution = (lon.max()-lon.min())/len(lon)\n",
    "    else:\n",
    "        coord_transformer = CoordinateTransformer(\n",
    "            lon.shape[1:], config[\"agg_fact\"])\n",
    "    trackstats_data.close()\n",
    "    tracknumbers_data.close()\n",
    "    cloudtrack_data.close()\n",
    "    # print(append_start_time-loop_start_time)\n",
    "    cloud_arr = np.empty((n_tracks), dtype=Cloud)\n",
    "    # Cloud(f'{temp_ind}_{i}') for i in range(n_tracks)])\n",
    "    # print(append_end_time-append_start_time)\n",
    "    # print(f\"Analyzing T: {min_temp} to {max_temp} Agg={config['agg_fact']}\")\n",
    "    for fp_ind in range(len(basetimes)):\n",
    "        time = basetimes[fp_ind]\n",
    "        time_str = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        print(f'{min_temp} to {max_temp} Loading {time_str}')\n",
    "        if collect_cot:\n",
    "            cot_field,cwp_field = extract_cpp_vars(time, pole)\n",
    "            ctp_field  = extract_ctx_vars(time, pole)\n",
    "        cloudtrack_fp = tracking_fps[pole][temp_key]['cloudtracks'][fp_ind]\n",
    "        cloudtrack_data = xr.load_dataset(cloudtrack_fp)\n",
    "        cloudtracknumber_field = extract_cloud_number_field(cloudtrack_data)\n",
    "        cph_field = cloudtrack_data['cph_filtered']\n",
    "        cloud_id_in_field, counts = np.unique(\n",
    "            cloudtracknumber_field, return_counts=True)\n",
    "        counts = counts[cloud_id_in_field != 0]\n",
    "        if len(counts) == 0:\n",
    "            continue\n",
    "        cloud_id_in_field = cloud_id_in_field[cloud_id_in_field != 0]\n",
    "        max_allowed_cloud_size_px = config['fast_mode_arr_size'] if config['postprocessing_fast_mode'] else counts.max(\n",
    "        )\n",
    "        hash_map_cloud_numbers = extract_cloud_coordinates(\n",
    "            cloudtracknumber_field, cloud_id_in_field, max_allowed_cloud_size_px)  # counts.max())\n",
    "        cloudtrack_data.close()\n",
    "        if max_allowed_cloud_size_px > 1000000:\n",
    "            print(np.where(counts, counts == counts.max()))\n",
    "        # print(cloud_id_in_field)\n",
    "        for track_number in cloud_id_in_field:\n",
    "            try:\n",
    "                if cloud_arr[track_number-1] is None:\n",
    "                    cloud_arr[track_number-1] = Cloud(temp_key, is_resampled)\n",
    "            except:\n",
    "                print(\n",
    "                    f\"Error: {temp_ind,track_number,len(cloud_arr)}\")\n",
    "                continue\n",
    "\n",
    "            if (not cloud_arr[track_number-1].terminate_cloud):\n",
    "                # TODO:SPEED UP NEXT TWO LINES (set_cloud_values and update_status)\n",
    "                ind, cord = hash_map_cloud_numbers[track_number]\n",
    "                cloud_location_ind = [cord[0, :ind], cord[1, :ind]]\n",
    "                if cloud_location_ind[0].size != 0:\n",
    "                    cloud_cph_values = cph_field.values[0,\n",
    "                                                        cloud_location_ind[0].T, cloud_location_ind[1].T]\n",
    "                    if is_resampled:\n",
    "                        avg_lat_ind = int(\n",
    "                            round(np.mean(cloud_location_ind[0])))\n",
    "                        avg_lon_ind = int(\n",
    "                            round(np.mean(cloud_location_ind[1])))\n",
    "                        # TODO:SPEED UP NEXT TWO LINES (set_cloud_values and update_status)\n",
    "                        cloud_arr[track_number-1].update_status(\n",
    "                            time, cloud_cph_values, extract_value(lat[avg_lat_ind]), extract_value(lon[avg_lon_ind]), pixel_area=lat_resolution.values*lon_resolution.values)\n",
    "                    else:\n",
    "                        cloud_location_ind_non_agg = coord_transformer.transform(\n",
    "                            cloud_location_ind[0], cloud_location_ind[1])\n",
    "                        cloud_cph_values = cph_field.values[0,\n",
    "                                                            cloud_location_ind[0].T, cloud_location_ind[1].T]\n",
    "                        cloud_pix_area_values = pix_area.values[0,\n",
    "                                                                cloud_location_ind_non_agg[0], cloud_location_ind_non_agg[1]]\n",
    "                        cloud_lat_values = lat.values[0,\n",
    "                                                      cloud_location_ind_non_agg[0], cloud_location_ind_non_agg[1]]\n",
    "                        cloud_lon_values = lon.values[0,\n",
    "                                                      cloud_location_ind_non_agg[0], cloud_location_ind_non_agg[1]]\n",
    "                        if collect_cot:\n",
    "                            cloud_cot_values = cot_field.values[0,\n",
    "                                                                cloud_location_ind_non_agg[0], cloud_location_ind_non_agg[1]]\n",
    "                            cloud_ctp_values = ctp_field.values[0,\n",
    "                                                                cloud_location_ind_non_agg[0], cloud_location_ind_non_agg[1]]\n",
    "                        else:\n",
    "                            cloud_cot_values = snp.array([0])\n",
    "                            cloud_ctp_values = np.array([0])\n",
    "                        # print(np.info(cloud_cot_values))\n",
    "                        cloud_arr[track_number-1].update_status(\n",
    "                            time, cloud_cph_values, cloud_cot_values, cloud_ctp_values, cloud_lat_values, cloud_lon_values, cloud_pix_area_values)\n",
    "                        \n",
    "                else:\n",
    "                    cloud_arr[track_number-1].update_missing_cloud()\n",
    "    save_single_temp_range_results(cloud_arr, pole, min_temp, max_temp, config)\n",
    "\n",
    "\n",
    "def analize_single_pole(pole, cloud_dict, tracking_fps, config, n_procs=3):\n",
    "    print(f\"Analyzing {pole}\")\n",
    "    aux_ds = xr.load_dataset(config[\"aux_fps_eu\"][pole], decode_times=False)\n",
    "    if config[\"Resample\"]:\n",
    "        with NestablePool(n_procs) as pool:\n",
    "            part_single_temp_range = partial(\n",
    "                analize_single_temp_range, cloud_dict=cloud_dict, tracking_fps=tracking_fps, pole=pole, config=config)\n",
    "            pool.map(part_single_temp_range, range(\n",
    "                len(config['min_temp_arr'])))\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "    if not config[\"Resample\"]:\n",
    "        lat_mat = aux_ds[\"lat\"].load()\n",
    "        lon_mat = aux_ds[\"lon\"].load()\n",
    "        pix_area = aux_ds[\"pixel_area\"].load()\n",
    "        with NestablePool(n_procs) as pool:\n",
    "            part_single_temp_range = partial(\n",
    "                analize_single_temp_range, cloud_dict=cloud_dict, tracking_fps=tracking_fps, pole=pole, config=config, pix_area=pix_area, lon=lon_mat, lat=lat_mat)\n",
    "            pool.map(part_single_temp_range, range(\n",
    "                len(config['min_temp_arr'])))\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "\n",
    "\n",
    "def save_results(res_dict, config):\n",
    "    min_temp, max_temp = config['min_temp_arr'][0], config['max_temp_arr'][0]\n",
    "    temp_key = f'{abs(round(min_temp))}_{abs(round(max_temp))}'\n",
    "    # cloudtrack_data = xr.(\n",
    "    #     tracking_fps['np'][temp_key][\"cloudtracks\"][0])\n",
    "    # lat = cloudtrack_data['lat']\n",
    "    # lon = cloudtrack_data['lon']\n",
    "    # lat_resolution = extract_value((lat.max()-lat.min())/len(lat))\n",
    "    # lon_resolution = extract_value((lon.max()-lon.min())/len(lon))\n",
    "    # cloudtrack_data.close()\n",
    "    columns = [\"is_liq\", \"is_mix\", \"is_ice\", \"max_water_frac\",\n",
    "               \"max_ice_fraction\", \"avg_size[km]\", \"max_size[km]\",\n",
    "               \"min_size[km]\", \"avg_size[px]\", \"max_size[px]\",\n",
    "               \"min_size[px]\", \"track_start_time\", \"track_length\",\n",
    "               \"glaciation_start_time\", \"glaciation_end_time\", \"avg_lat\",\n",
    "               \"avg_lon\", \"start_ice_fraction\", \"end_ice_fraction\",\n",
    "               \"ice_frac_hist\", \"cot_hist\", \"lat_hist\", \"lon_hist\",\n",
    "               \"size_hist_km\"]\n",
    "    datapoints_per_cloud = len(columns)\n",
    "    # Iterating through the cloud data\n",
    "    for temp_ind in range(len(config['max_temp_arr'])):\n",
    "        for pole in config['pole_folders']:\n",
    "            min_temp, max_temp = config['min_temp_arr'][temp_ind], config['max_temp_arr'][temp_ind]\n",
    "            temp_key = f'{abs(round(min_temp))}_{abs(round(max_temp))}'\n",
    "            key = f'{pole}_{temp_key}'\n",
    "            cloud_arr = res_dict[key]\n",
    "\n",
    "            cloudinfo_df = pd.DataFrame(\n",
    "                index=range(len(cloud_arr)), columns=columns)\n",
    "            for cloud_ind in range(len(cloud_arr)):\n",
    "                current_cloud = cloud_arr[cloud_ind]\n",
    "                if current_cloud is not None:\n",
    "                    cloudinfo_df.iloc[cloud_ind] = [\n",
    "                        current_cloud.\n",
    "                        current_cloud.is_liq,\n",
    "                        current_cloud.is_mix,\n",
    "                        current_cloud.is_ice,\n",
    "                        current_cloud.max_water_fraction,\n",
    "                        current_cloud.max_ice_fraction,\n",
    "                        extract_value(current_cloud.avg_cloud_size_km),\n",
    "                        extract_value(current_cloud.max_size_km),\n",
    "                        extract_value(current_cloud.min_size_km),\n",
    "                        extract_value(current_cloud.avg_cloud_size_px),\n",
    "                        extract_value(current_cloud.max_size_px),\n",
    "                        extract_value(current_cloud.min_size_px),\n",
    "                        current_cloud.track_start_time,\n",
    "                        current_cloud.track_length,\n",
    "                        current_cloud.glaciation_start_time,\n",
    "                        current_cloud.glaciation_end_time,\n",
    "                        extract_value(current_cloud.avg_cloud_lat),\n",
    "                        extract_value(current_cloud.avg_cloud_lon),\n",
    "                        current_cloud.start_ice_fraction_arr,\n",
    "                        current_cloud.end_ice_fraction_arr,\n",
    "                        current_cloud.ice_fraction_list,\n",
    "                        current_cloud.mean_cot_list,\n",
    "                        current_cloud.lat_list,\n",
    "                        current_cloud.lon_list,\n",
    "                        current_cloud.cloud_size_km_list\n",
    "                    ]\n",
    "\n",
    "            # Ensure output directory exists\n",
    "            output_dir = os.path.join(\n",
    "                config['postprocessing_output_dir'],\n",
    "                config['time_folder_name'],\n",
    "                f\"T_{abs(round(min_temp)):02}_{abs(round(max_temp)):02}_agg_{config['agg_fact']:02}\"\n",
    "            )\n",
    "            os.makedirs(os.path.dirname(output_dir), exist_ok=True)\n",
    "\n",
    "            # Save DataFrame to Parquet\n",
    "            output_dir_parq = output_dir + \".parquet\"\n",
    "            print(\"Writing to \", output_dir_parq)\n",
    "            cloudinfo_df.to_parquet(output_dir_parq)\n",
    "\n",
    "            # Optionally save as CSV\n",
    "            if config['write_csv']:\n",
    "                output_dir_csv = output_dir + \".csv\"\n",
    "                cloudinfo_df.to_csv(output_dir_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing np\n",
      "Analyzing np 5_0\n",
      "Analyzing np 10_5\n",
      "Analyzing np 15_10\n",
      "-5 to 0 Loading 20240101_000000\n",
      "-15 to -10 Loading 20240101_000000\n",
      "-10 to -5 Loading 20240101_000000\n",
      "-15 to -10 Loading 20240101_001500-5 to 0 Loading 20240101_001500\n",
      "\n",
      "-10 to -5 Loading 20240101_001500\n",
      "-10 to -5 Loading 20240101_003000\n",
      "-15 to -10 Loading 20240101_003000\n",
      "-5 to 0 Loading 20240101_003000\n",
      "-15 to -10 Loading 20240101_004500\n",
      "-5 to 0 Loading 20240101_004500\n",
      "-10 to -5 Loading 20240101_004500\n",
      "-10 to -5 Loading 20240101_010000\n",
      "-15 to -10 Loading 20240101_010000\n",
      "-5 to 0 Loading 20240101_010000\n",
      "-10 to -5 Loading 20240101_011500\n",
      "-5 to 0 Loading 20240101_011500\n",
      "-15 to -10 Loading 20240101_011500\n",
      "-15 to -10 Loading 20240101_013000\n",
      "-5 to 0 Loading 20240101_013000\n",
      "-10 to -5 Loading 20240101_013000\n",
      "-10 to -5 Loading 20240101_014500\n",
      "-15 to -10 Loading 20240101_014500\n",
      "-5 to 0 Loading 20240101_014500\n",
      "-5 to 0 Loading 20240101_020000\n",
      "-15 to -10 Loading 20240101_020000\n",
      "-10 to -5 Loading 20240101_020000\n",
      "-5 to 0 Loading 20240101_021500\n",
      "-15 to -10 Loading 20240101_021500\n",
      "-10 to -5 Loading 20240101_021500\n",
      "-5 to 0 Loading 20240101_023000\n",
      "-15 to -10 Loading 20240101_023000\n",
      "-10 to -5 Loading 20240101_023000\n",
      "-15 to -10 Loading 20240101_024500-5 to 0 Loading 20240101_024500\n",
      "\n",
      "-10 to -5 Loading 20240101_024500\n",
      "-5 to 0 Loading 20240101_030000\n",
      "-15 to -10 Loading 20240101_030000\n",
      "-10 to -5 Loading 20240101_030000\n",
      "-10 to -5 Loading 20240101_031500\n",
      "-15 to -10 Loading 20240101_031500\n",
      "-5 to 0 Loading 20240101_031500\n",
      "-5 to 0 Loading 20240101_033000\n",
      "-15 to -10 Loading 20240101_033000\n",
      "-10 to -5 Loading 20240101_033000\n",
      "-5 to 0 Loading 20240101_034500\n",
      "-15 to -10 Loading 20240101_034500\n",
      "-10 to -5 Loading 20240101_034500\n",
      "-5 to 0 Loading 20240101_040000\n",
      "-10 to -5 Loading 20240101_040000\n",
      "-15 to -10 Loading 20240101_040000\n",
      "-5 to 0 Loading 20240101_041500\n",
      "-10 to -5 Loading 20240101_041500\n",
      "-15 to -10 Loading 20240101_041500\n",
      "-5 to 0 Loading 20240101_043000-10 to -5 Loading 20240101_043000\n",
      "\n",
      "-15 to -10 Loading 20240101_043000\n",
      "-15 to -10 Loading 20240101_044500\n",
      "-10 to -5 Loading 20240101_044500\n",
      "-5 to 0 Loading 20240101_044500\n",
      "-15 to -10 Loading 20240101_050000\n",
      "-5 to 0 Loading 20240101_050000\n",
      "-10 to -5 Loading 20240101_050000\n",
      "-5 to 0 Loading 20240101_051500\n",
      "-15 to -10 Loading 20240101_051500\n",
      "-10 to -5 Loading 20240101_051500\n",
      "-15 to -10 Loading 20240101_053000\n",
      "-5 to 0 Loading 20240101_053000\n",
      "-10 to -5 Loading 20240101_053000\n",
      "-5 to 0 Loading 20240101_054500\n",
      "-15 to -10 Loading 20240101_054500\n",
      "-10 to -5 Loading 20240101_054500\n",
      "-5 to 0 Loading 20240101_060000-10 to -5 Loading 20240101_060000\n",
      "\n",
      "-15 to -10 Loading 20240101_060000\n",
      "-5 to 0 Loading 20240101_061500\n",
      "-10 to -5 Loading 20240101_061500\n",
      "-15 to -10 Loading 20240101_061500\n",
      "-15 to -10 Loading 20240101_063000\n",
      "-5 to 0 Loading 20240101_063000\n",
      "-10 to -5 Loading 20240101_063000\n",
      "-5 to 0 Loading 20240101_064500\n",
      "-15 to -10 Loading 20240101_064500\n",
      "-10 to -5 Loading 20240101_064500\n",
      "-15 to -10 Loading 20240101_070000\n",
      "-5 to 0 Loading 20240101_070000-10 to -5 Loading 20240101_070000\n",
      "\n",
      "-5 to 0 Loading 20240101_071500\n",
      "-15 to -10 Loading 20240101_071500\n",
      "-10 to -5 Loading 20240101_071500\n",
      "-10 to -5 Loading 20240101_073000\n",
      "-15 to -10 Loading 20240101_073000\n",
      "-5 to 0 Loading 20240101_073000\n",
      "-15 to -10 Loading 20240101_074500\n",
      "-10 to -5 Loading 20240101_074500\n",
      "-5 to 0 Loading 20240101_074500\n",
      "-5 to 0 Loading 20240101_080000\n",
      "-10 to -5 Loading 20240101_080000\n",
      "-15 to -10 Loading 20240101_080000\n",
      "-5 to 0 Loading 20240101_081500\n",
      "-10 to -5 Loading 20240101_081500\n",
      "-15 to -10 Loading 20240101_081500\n",
      "-15 to -10 Loading 20240101_083000\n",
      "-10 to -5 Loading 20240101_083000\n",
      "-5 to 0 Loading 20240101_083000\n",
      "-10 to -5 Loading 20240101_084500\n",
      "-15 to -10 Loading 20240101_084500\n",
      "-5 to 0 Loading 20240101_084500\n",
      "-5 to 0 Loading 20240101_090000-15 to -10 Loading 20240101_090000\n",
      "\n",
      "-10 to -5 Loading 20240101_090000\n",
      "-15 to -10 Loading 20240101_091500\n",
      "-10 to -5 Loading 20240101_091500\n",
      "-5 to 0 Loading 20240101_091500-15 to -10 Loading 20240101_093000\n",
      "\n",
      "-10 to -5 Loading 20240101_093000\n",
      "-15 to -10 Loading 20240101_094500-10 to -5 Loading 20240101_094500-5 to 0 Loading 20240101_093000\n",
      "\n",
      "\n",
      "-15 to -10 Loading 20240101_100000-10 to -5 Loading 20240101_100000\n",
      "-5 to 0 Loading 20240101_094500\n",
      "\n",
      "-5 to 0 Loading 20240101_100000\n",
      "-10 to -5 Loading 20240101_101500\n",
      "-15 to -10 Loading 20240101_101500\n",
      "-5 to 0 Loading 20240101_101500\n",
      "-10 to -5 Loading 20240101_103000\n",
      "-15 to -10 Loading 20240101_103000\n",
      "-5 to 0 Loading 20240101_103000\n",
      "-5 to 0 Loading 20240101_104500\n",
      "-15 to -10 Loading 20240101_104500\n",
      "-10 to -5 Loading 20240101_104500\n",
      "-5 to 0 Loading 20240101_110000\n",
      "-15 to -10 Loading 20240101_110000\n",
      "-10 to -5 Loading 20240101_110000\n",
      "-5 to 0 Loading 20240101_111500\n",
      "-15 to -10 Loading 20240101_111500\n",
      "-10 to -5 Loading 20240101_111500\n",
      "-10 to -5 Loading 20240101_113000\n",
      "-15 to -10 Loading 20240101_113000\n",
      "-5 to 0 Loading 20240101_113000\n",
      "-5 to 0 Loading 20240101_114500-15 to -10 Loading 20240101_114500-10 to -5 Loading 20240101_114500\n",
      "\n",
      "\n",
      "-10 to -5 Loading 20240101_120000\n",
      "-5 to 0 Loading 20240101_120000\n",
      "-15 to -10 Loading 20240101_120000\n",
      "-5 to 0 Loading 20240101_121500\n",
      "-10 to -5 Loading 20240101_121500\n",
      "-15 to -10 Loading 20240101_121500\n",
      "-10 to -5 Loading 20240101_123000-5 to 0 Loading 20240101_123000\n",
      "\n",
      "-15 to -10 Loading 20240101_123000\n",
      "-5 to 0 Loading 20240101_124500\n",
      "-15 to -10 Loading 20240101_124500\n",
      "-10 to -5 Loading 20240101_124500\n",
      "-5 to 0 Loading 20240101_130000-15 to -10 Loading 20240101_130000\n",
      "-10 to -5 Loading 20240101_130000\n",
      "\n",
      "-15 to -10 Loading 20240101_131500\n",
      "-5 to 0 Loading 20240101_131500\n",
      "-10 to -5 Loading 20240101_131500\n",
      "-5 to 0 Loading 20240101_133000-15 to -10 Loading 20240101_133000\n",
      "\n",
      "-10 to -5 Loading 20240101_133000\n",
      "-15 to -10 Loading 20240101_134500\n",
      "-5 to 0 Loading 20240101_134500\n",
      "-10 to -5 Loading 20240101_134500\n",
      "-15 to -10 Loading 20240101_140000\n",
      "-5 to 0 Loading 20240101_140000\n",
      "-10 to -5 Loading 20240101_140000\n",
      "-15 to -10 Loading 20240101_141500\n",
      "-5 to 0 Loading 20240101_141500\n",
      "-10 to -5 Loading 20240101_141500\n",
      "-15 to -10 Loading 20240101_143000\n",
      "-5 to 0 Loading 20240101_143000\n",
      "-15 to -10 Loading 20240101_144500\n",
      "-5 to 0 Loading 20240101_144500\n",
      "-10 to -5 Loading 20240101_143000\n",
      "-10 to -5 Loading 20240101_144500\n",
      "-15 to -10 Loading 20240101_150000\n",
      "-5 to 0 Loading 20240101_150000\n",
      "-10 to -5 Loading 20240101_150000\n",
      "-15 to -10 Loading 20240101_151500\n",
      "-5 to 0 Loading 20240101_151500\n",
      "-10 to -5 Loading 20240101_151500\n",
      "-5 to 0 Loading 20240101_153000\n",
      "-15 to -10 Loading 20240101_153000\n",
      "-10 to -5 Loading 20240101_153000\n",
      "-15 to -10 Loading 20240101_154500\n",
      "-5 to 0 Loading 20240101_154500\n",
      "-15 to -10 Loading 20240101_160000\n",
      "-5 to 0 Loading 20240101_160000\n",
      "-10 to -5 Loading 20240101_154500\n",
      "-10 to -5 Loading 20240101_160000\n",
      "-5 to 0 Loading 20240101_161500\n",
      "-15 to -10 Loading 20240101_161500\n",
      "-10 to -5 Loading 20240101_161500\n",
      "-5 to 0 Loading 20240101_163000\n",
      "-15 to -10 Loading 20240101_163000\n",
      "-10 to -5 Loading 20240101_163000\n",
      "-15 to -10 Loading 20240101_164500\n",
      "-5 to 0 Loading 20240101_164500\n",
      "-10 to -5 Loading 20240101_164500\n",
      "-15 to -10 Loading 20240101_170000\n",
      "-5 to 0 Loading 20240101_170000\n",
      "-10 to -5 Loading 20240101_170000\n",
      "-15 to -10 Loading 20240101_171500\n",
      "-5 to 0 Loading 20240101_171500\n",
      "-10 to -5 Loading 20240101_171500\n",
      "-15 to -10 Loading 20240101_173000\n",
      "-5 to 0 Loading 20240101_173000\n",
      "-10 to -5 Loading 20240101_173000\n",
      "-15 to -10 Loading 20240101_174500\n",
      "-5 to 0 Loading 20240101_174500\n",
      "-15 to -10 Loading 20240101_180000\n",
      "-5 to 0 Loading 20240101_180000\n",
      "-10 to -5 Loading 20240101_174500\n",
      "-15 to -10 Loading 20240101_181500\n",
      "-5 to 0 Loading 20240101_181500\n",
      "-10 to -5 Loading 20240101_180000\n",
      "-5 to 0 Loading 20240101_183000\n",
      "-15 to -10 Loading 20240101_183000\n",
      "-10 to -5 Loading 20240101_181500\n",
      "-5 to 0 Loading 20240101_184500\n",
      "-15 to -10 Loading 20240101_184500\n",
      "-10 to -5 Loading 20240101_183000\n",
      "-15 to -10 Loading 20240101_190000\n",
      "-5 to 0 Loading 20240101_190000\n",
      "-10 to -5 Loading 20240101_184500\n",
      "-15 to -10 Loading 20240101_191500\n",
      "-5 to 0 Loading 20240101_191500\n",
      "-10 to -5 Loading 20240101_190000\n",
      "-5 to 0 Loading 20240101_193000\n",
      "-15 to -10 Loading 20240101_193000\n",
      "-10 to -5 Loading 20240101_191500\n",
      "-15 to -10 Loading 20240101_194500\n",
      "-5 to 0 Loading 20240101_194500\n",
      "-10 to -5 Loading 20240101_193000\n",
      "-5 to 0 Loading 20240101_200000\n",
      "-15 to -10 Loading 20240101_200000\n",
      "-10 to -5 Loading 20240101_194500\n",
      "-15 to -10 Loading 20240101_201500-5 to 0 Loading 20240101_201500\n",
      "\n",
      "-10 to -5 Loading 20240101_200000\n",
      "-5 to 0 Loading 20240101_203000\n",
      "-15 to -10 Loading 20240101_203000\n",
      "-10 to -5 Loading 20240101_201500\n",
      "-15 to -10 Loading 20240101_204500\n",
      "-10 to -5 Loading 20240101_203000\n",
      "-5 to 0 Loading 20240101_204500\n",
      "-10 to -5 Loading 20240101_204500\n",
      "-5 to 0 Loading 20240101_210000\n",
      "-15 to -10 Loading 20240101_210000\n",
      "-10 to -5 Loading 20240101_210000\n",
      "-5 to 0 Loading 20240101_211500\n",
      "-15 to -10 Loading 20240101_211500\n",
      "-10 to -5 Loading 20240101_211500\n",
      "-15 to -10 Loading 20240101_213000\n",
      "-10 to -5 Loading 20240101_213000\n",
      "-5 to 0 Loading 20240101_213000\n",
      "-15 to -10 Loading 20240101_214500\n",
      "-5 to 0 Loading 20240101_214500\n",
      "-10 to -5 Loading 20240101_214500\n",
      "-10 to -5 Loading 20240101_220000\n",
      "-15 to -10 Loading 20240101_220000\n",
      "-5 to 0 Loading 20240101_220000\n",
      "-5 to 0 Loading 20240101_221500\n",
      "-15 to -10 Loading 20240101_221500\n",
      "-10 to -5 Loading 20240101_221500\n",
      "-5 to 0 Loading 20240101_223000\n",
      "-10 to -5 Loading 20240101_223000\n",
      "-15 to -10 Loading 20240101_223000\n",
      "-10 to -5 Loading 20240101_224500\n",
      "-5 to 0 Loading 20240101_224500\n",
      "-15 to -10 Loading 20240101_224500\n",
      "-10 to -5 Loading 20240101_230000\n",
      "-15 to -10 Loading 20240101_230000\n",
      "-5 to 0 Loading 20240101_230000\n",
      "-15 to -10 Loading 20240101_231500-5 to 0 Loading 20240101_231500\n",
      "\n",
      "-10 to -5 Loading 20240101_231500\n",
      "-15 to -10 Loading 20240101_233000-5 to 0 Loading 20240101_233000-10 to -5 Loading 20240101_233000\n",
      "\n",
      "\n",
      "-15 to -10 Loading 20240101_234500\n",
      "-10 to -5 Loading 20240101_234500\n",
      "-5 to 0 Loading 20240101_234500\n",
      "-5 to 0 Loading 20240102_000000\n",
      "-10 to -5 Loading 20240102_000000\n",
      "-15 to -10 Loading 20240102_000000\n",
      "Writing to  Writing to /cluster/work/climate/dnikolo/Cloud_analysis/np/20240101.0000_20240102.0000/Agg_03_T_05_00.parquetWriting to  \n",
      " /cluster/work/climate/dnikolo/Cloud_analysis/np/20240101.0000_20240102.0000/Agg_03_T_15_10.parquet/cluster/work/climate/dnikolo/Cloud_analysis/np/20240101.0000_20240102.0000/Agg_03_T_10_05.parquet\n",
      "\n",
      "Analyzing np 20_15\n",
      "Analyzing np 25_20\n",
      "Analyzing np 30_25\n",
      "-25 to -20 Loading 20240101_000000\n",
      "-20 to -15 Loading 20240101_000000\n",
      "-30 to -25 Loading 20240101_000000\n",
      "-25 to -20 Loading 20240101_001500\n",
      "-20 to -15 Loading 20240101_001500\n",
      "-30 to -25 Loading 20240101_001500\n",
      "-20 to -15 Loading 20240101_003000\n",
      "-25 to -20 Loading 20240101_003000\n",
      "-30 to -25 Loading 20240101_003000\n",
      "-25 to -20 Loading 20240101_004500\n",
      "-20 to -15 Loading 20240101_004500\n",
      "-30 to -25 Loading 20240101_004500\n",
      "-25 to -20 Loading 20240101_010000\n",
      "-20 to -15 Loading 20240101_010000\n",
      "-30 to -25 Loading 20240101_010000\n",
      "-25 to -20 Loading 20240101_011500\n",
      "-20 to -15 Loading 20240101_011500-30 to -25 Loading 20240101_011500\n",
      "\n",
      "-25 to -20 Loading 20240101_013000\n",
      "-30 to -25 Loading 20240101_013000\n",
      "-20 to -15 Loading 20240101_013000\n",
      "-25 to -20 Loading 20240101_014500\n",
      "-30 to -25 Loading 20240101_014500\n",
      "-20 to -15 Loading 20240101_014500\n",
      "-25 to -20 Loading 20240101_020000\n",
      "-30 to -25 Loading 20240101_020000\n",
      "-20 to -15 Loading 20240101_020000\n",
      "-30 to -25 Loading 20240101_021500\n",
      "-25 to -20 Loading 20240101_021500\n",
      "-20 to -15 Loading 20240101_021500\n",
      "-30 to -25 Loading 20240101_023000\n",
      "-25 to -20 Loading 20240101_023000\n",
      "-20 to -15 Loading 20240101_023000\n",
      "-30 to -25 Loading 20240101_024500-25 to -20 Loading 20240101_024500\n",
      "\n",
      "-20 to -15 Loading 20240101_024500\n",
      "-30 to -25 Loading 20240101_030000\n",
      "-25 to -20 Loading 20240101_030000\n",
      "-20 to -15 Loading 20240101_030000\n",
      "-20 to -15 Loading 20240101_031500\n",
      "-25 to -20 Loading 20240101_031500-30 to -25 Loading 20240101_031500\n",
      "\n",
      "-25 to -20 Loading 20240101_033000\n",
      "-20 to -15 Loading 20240101_033000\n",
      "-30 to -25 Loading 20240101_033000\n",
      "-25 to -20 Loading 20240101_034500\n",
      "-30 to -25 Loading 20240101_034500\n",
      "-20 to -15 Loading 20240101_034500\n",
      "-25 to -20 Loading 20240101_040000\n",
      "-30 to -25 Loading 20240101_040000\n",
      "-20 to -15 Loading 20240101_040000\n",
      "-20 to -15 Loading 20240101_041500\n",
      "-25 to -20 Loading 20240101_041500\n",
      "-30 to -25 Loading 20240101_041500\n",
      "-30 to -25 Loading 20240101_043000\n",
      "-25 to -20 Loading 20240101_043000\n",
      "-20 to -15 Loading 20240101_043000\n",
      "-30 to -25 Loading 20240101_044500\n",
      "-25 to -20 Loading 20240101_044500\n",
      "-20 to -15 Loading 20240101_044500\n",
      "-20 to -15 Loading 20240101_050000\n",
      "-30 to -25 Loading 20240101_050000\n",
      "-25 to -20 Loading 20240101_050000\n",
      "-25 to -20 Loading 20240101_051500\n",
      "-30 to -25 Loading 20240101_051500\n",
      "-20 to -15 Loading 20240101_051500\n",
      "-30 to -25 Loading 20240101_053000\n",
      "-25 to -20 Loading 20240101_053000\n",
      "-20 to -15 Loading 20240101_053000\n",
      "-25 to -20 Loading 20240101_054500\n",
      "-20 to -15 Loading 20240101_054500\n",
      "-30 to -25 Loading 20240101_054500\n",
      "-30 to -25 Loading 20240101_060000\n",
      "-25 to -20 Loading 20240101_060000\n",
      "-20 to -15 Loading 20240101_060000\n",
      "-30 to -25 Loading 20240101_061500\n",
      "-25 to -20 Loading 20240101_061500\n",
      "-20 to -15 Loading 20240101_061500\n",
      "-25 to -20 Loading 20240101_063000\n",
      "-30 to -25 Loading 20240101_063000\n",
      "-20 to -15 Loading 20240101_063000\n",
      "-25 to -20 Loading 20240101_064500-30 to -25 Loading 20240101_064500\n",
      "\n",
      "-20 to -15 Loading 20240101_064500\n",
      "-20 to -15 Loading 20240101_070000-30 to -25 Loading 20240101_070000\n",
      "\n",
      "-25 to -20 Loading 20240101_070000\n",
      "-20 to -15 Loading 20240101_071500\n",
      "-30 to -25 Loading 20240101_071500\n",
      "-25 to -20 Loading 20240101_071500\n",
      "-25 to -20 Loading 20240101_073000\n",
      "-30 to -25 Loading 20240101_073000\n",
      "-20 to -15 Loading 20240101_073000\n",
      "-20 to -15 Loading 20240101_074500\n",
      "-25 to -20 Loading 20240101_074500\n",
      "-30 to -25 Loading 20240101_074500\n",
      "-20 to -15 Loading 20240101_080000\n",
      "-25 to -20 Loading 20240101_080000\n",
      "-30 to -25 Loading 20240101_080000\n",
      "-30 to -25 Loading 20240101_081500\n",
      "-25 to -20 Loading 20240101_081500\n",
      "-20 to -15 Loading 20240101_081500\n",
      "-25 to -20 Loading 20240101_083000\n",
      "-20 to -15 Loading 20240101_083000\n",
      "-30 to -25 Loading 20240101_083000\n",
      "-25 to -20 Loading 20240101_084500\n",
      "-20 to -15 Loading 20240101_084500\n",
      "-30 to -25 Loading 20240101_084500\n",
      "-30 to -25 Loading 20240101_090000\n",
      "-20 to -15 Loading 20240101_090000\n",
      "-20 to -15 Loading 20240101_091500\n",
      "-30 to -25 Loading 20240101_091500\n",
      "-30 to -25 Loading 20240101_093000\n",
      "-20 to -15 Loading 20240101_093000\n",
      "-25 to -20 Loading 20240101_090000\n",
      "-25 to -20 Loading 20240101_091500\n",
      "-30 to -25 Loading 20240101_094500\n",
      "-20 to -15 Loading 20240101_094500\n",
      "-25 to -20 Loading 20240101_093000\n",
      "-20 to -15 Loading 20240101_100000\n",
      "-30 to -25 Loading 20240101_100000\n",
      "-25 to -20 Loading 20240101_094500\n",
      "-20 to -15 Loading 20240101_101500\n",
      "-30 to -25 Loading 20240101_101500\n",
      "-25 to -20 Loading 20240101_100000\n",
      "-20 to -15 Loading 20240101_103000-30 to -25 Loading 20240101_103000\n",
      "\n",
      "-25 to -20 Loading 20240101_101500\n",
      "-30 to -25 Loading 20240101_104500\n",
      "-20 to -15 Loading 20240101_104500\n",
      "-25 to -20 Loading 20240101_103000\n",
      "-25 to -20 Loading 20240101_104500\n",
      "-20 to -15 Loading 20240101_110000\n",
      "-30 to -25 Loading 20240101_110000\n",
      "-25 to -20 Loading 20240101_110000\n",
      "-20 to -15 Loading 20240101_111500\n",
      "-30 to -25 Loading 20240101_111500\n",
      "-30 to -25 Loading 20240101_113000\n",
      "-25 to -20 Loading 20240101_111500\n",
      "-20 to -15 Loading 20240101_113000\n",
      "-25 to -20 Loading 20240101_113000\n",
      "-20 to -15 Loading 20240101_114500\n",
      "-30 to -25 Loading 20240101_114500\n",
      "-25 to -20 Loading 20240101_114500\n",
      "-30 to -25 Loading 20240101_120000-20 to -15 Loading 20240101_120000\n",
      "\n",
      "-25 to -20 Loading 20240101_120000\n",
      "-20 to -15 Loading 20240101_121500\n",
      "-30 to -25 Loading 20240101_121500\n",
      "-25 to -20 Loading 20240101_121500\n",
      "-20 to -15 Loading 20240101_123000\n",
      "-30 to -25 Loading 20240101_123000\n",
      "-25 to -20 Loading 20240101_123000\n",
      "-20 to -15 Loading 20240101_124500\n",
      "-30 to -25 Loading 20240101_124500\n",
      "-25 to -20 Loading 20240101_124500\n",
      "-30 to -25 Loading 20240101_130000\n",
      "-20 to -15 Loading 20240101_130000\n",
      "-25 to -20 Loading 20240101_130000\n",
      "-30 to -25 Loading 20240101_131500\n",
      "-20 to -15 Loading 20240101_131500\n",
      "-25 to -20 Loading 20240101_131500\n",
      "-30 to -25 Loading 20240101_133000\n",
      "-20 to -15 Loading 20240101_133000\n",
      "-25 to -20 Loading 20240101_133000\n",
      "-30 to -25 Loading 20240101_134500\n",
      "-20 to -15 Loading 20240101_134500\n",
      "-25 to -20 Loading 20240101_134500\n",
      "-20 to -15 Loading 20240101_140000\n",
      "-30 to -25 Loading 20240101_140000\n",
      "-25 to -20 Loading 20240101_140000\n",
      "-20 to -15 Loading 20240101_141500\n",
      "-30 to -25 Loading 20240101_141500\n",
      "-25 to -20 Loading 20240101_141500\n",
      "-20 to -15 Loading 20240101_143000\n",
      "-30 to -25 Loading 20240101_143000\n",
      "-25 to -20 Loading 20240101_143000\n",
      "-20 to -15 Loading 20240101_144500\n",
      "-30 to -25 Loading 20240101_144500\n",
      "-25 to -20 Loading 20240101_144500\n",
      "-20 to -15 Loading 20240101_150000\n",
      "-30 to -25 Loading 20240101_150000\n",
      "-25 to -20 Loading 20240101_150000\n",
      "-20 to -15 Loading 20240101_151500\n",
      "-30 to -25 Loading 20240101_151500\n",
      "-25 to -20 Loading 20240101_151500\n",
      "-20 to -15 Loading 20240101_153000\n",
      "-30 to -25 Loading 20240101_153000\n",
      "-25 to -20 Loading 20240101_153000\n",
      "-20 to -15 Loading 20240101_154500\n",
      "-30 to -25 Loading 20240101_154500\n",
      "-25 to -20 Loading 20240101_154500\n",
      "-30 to -25 Loading 20240101_160000\n",
      "-20 to -15 Loading 20240101_160000\n",
      "-25 to -20 Loading 20240101_160000\n",
      "-30 to -25 Loading 20240101_161500\n",
      "-20 to -15 Loading 20240101_161500\n",
      "-25 to -20 Loading 20240101_161500\n",
      "-20 to -15 Loading 20240101_163000\n",
      "-30 to -25 Loading 20240101_163000\n",
      "-25 to -20 Loading 20240101_163000\n",
      "-30 to -25 Loading 20240101_164500\n",
      "-20 to -15 Loading 20240101_164500\n",
      "-25 to -20 Loading 20240101_164500\n",
      "-30 to -25 Loading 20240101_170000\n",
      "-20 to -15 Loading 20240101_170000\n",
      "-25 to -20 Loading 20240101_170000\n",
      "-20 to -15 Loading 20240101_171500\n",
      "-30 to -25 Loading 20240101_171500\n",
      "-25 to -20 Loading 20240101_171500\n",
      "-20 to -15 Loading 20240101_173000\n",
      "-30 to -25 Loading 20240101_173000\n",
      "-25 to -20 Loading 20240101_173000\n",
      "-20 to -15 Loading 20240101_174500\n",
      "-30 to -25 Loading 20240101_174500\n",
      "-25 to -20 Loading 20240101_174500\n",
      "-20 to -15 Loading 20240101_180000\n",
      "-30 to -25 Loading 20240101_180000\n",
      "-25 to -20 Loading 20240101_180000\n",
      "-20 to -15 Loading 20240101_181500\n",
      "-30 to -25 Loading 20240101_181500\n",
      "-25 to -20 Loading 20240101_181500\n",
      "-20 to -15 Loading 20240101_183000\n",
      "-30 to -25 Loading 20240101_183000\n",
      "-25 to -20 Loading 20240101_183000\n",
      "-30 to -25 Loading 20240101_184500\n",
      "-20 to -15 Loading 20240101_184500\n",
      "-25 to -20 Loading 20240101_184500\n",
      "-30 to -25 Loading 20240101_190000\n",
      "-20 to -15 Loading 20240101_190000\n",
      "-25 to -20 Loading 20240101_190000\n",
      "-30 to -25 Loading 20240101_191500\n",
      "-20 to -15 Loading 20240101_191500\n",
      "-25 to -20 Loading 20240101_191500\n",
      "-30 to -25 Loading 20240101_193000\n",
      "-20 to -15 Loading 20240101_193000\n",
      "-25 to -20 Loading 20240101_193000\n",
      "-30 to -25 Loading 20240101_194500\n",
      "-20 to -15 Loading 20240101_194500\n",
      "-25 to -20 Loading 20240101_194500\n",
      "-20 to -15 Loading 20240101_200000\n",
      "-30 to -25 Loading 20240101_200000\n",
      "-25 to -20 Loading 20240101_200000\n",
      "-20 to -15 Loading 20240101_201500\n",
      "-30 to -25 Loading 20240101_201500\n",
      "-25 to -20 Loading 20240101_201500\n",
      "-25 to -20 Loading 20240101_203000\n",
      "-20 to -15 Loading 20240101_203000\n",
      "-30 to -25 Loading 20240101_203000\n",
      "-20 to -15 Loading 20240101_204500\n",
      "-25 to -20 Loading 20240101_204500\n",
      "-30 to -25 Loading 20240101_204500\n",
      "-20 to -15 Loading 20240101_210000\n",
      "-30 to -25 Loading 20240101_210000\n",
      "-25 to -20 Loading 20240101_210000\n",
      "-20 to -15 Loading 20240101_211500-25 to -20 Loading 20240101_211500-30 to -25 Loading 20240101_211500\n",
      "\n",
      "\n",
      "-20 to -15 Loading 20240101_213000\n",
      "-30 to -25 Loading 20240101_213000\n",
      "-25 to -20 Loading 20240101_213000\n",
      "-30 to -25 Loading 20240101_214500\n",
      "-20 to -15 Loading 20240101_214500\n",
      "-25 to -20 Loading 20240101_214500\n",
      "-20 to -15 Loading 20240101_220000\n",
      "-25 to -20 Loading 20240101_220000\n",
      "-30 to -25 Loading 20240101_220000\n",
      "-25 to -20 Loading 20240101_221500\n",
      "-20 to -15 Loading 20240101_221500\n",
      "-30 to -25 Loading 20240101_221500\n",
      "-25 to -20 Loading 20240101_223000\n",
      "-30 to -25 Loading 20240101_223000\n",
      "-20 to -15 Loading 20240101_223000\n",
      "-30 to -25 Loading 20240101_224500\n",
      "-20 to -15 Loading 20240101_224500\n",
      "-25 to -20 Loading 20240101_224500\n",
      "-30 to -25 Loading 20240101_230000\n",
      "-20 to -15 Loading 20240101_230000-25 to -20 Loading 20240101_230000\n",
      "\n",
      "-30 to -25 Loading 20240101_231500\n",
      "\n",
      "-25 to -20 Loading 20240101_231500-20 to -15 Loading 20240101_231500\n",
      "-30 to -25 Loading 20240101_233000\n",
      "-20 to -15 Loading 20240101_233000\n",
      "-25 to -20 Loading 20240101_233000\n",
      "-20 to -15 Loading 20240101_234500\n",
      "-30 to -25 Loading 20240101_234500\n",
      "-25 to -20 Loading 20240101_234500\n",
      "-20 to -15 Loading 20240102_000000\n",
      "-25 to -20 Loading 20240102_000000\n",
      "-30 to -25 Loading 20240102_000000\n",
      "Writing to Writing to  Writing to  /cluster/work/climate/dnikolo/Cloud_analysis/np/20240101.0000_20240102.0000/Agg_03_T_25_20.parquet \n",
      "/cluster/work/climate/dnikolo/Cloud_analysis/np/20240101.0000_20240102.0000/Agg_03_T_20_15.parquet/cluster/work/climate/dnikolo/Cloud_analysis/np/20240101.0000_20240102.0000/Agg_03_T_30_25.parquet\n",
      "\n",
      "Analyzing np 35_30\n",
      "-35 to -30 Loading 20240101_000000\n",
      "-35 to -30 Loading 20240101_001500\n",
      "-35 to -30 Loading 20240101_003000\n",
      "-35 to -30 Loading 20240101_004500\n",
      "-35 to -30 Loading 20240101_010000\n",
      "-35 to -30 Loading 20240101_011500\n",
      "-35 to -30 Loading 20240101_013000\n",
      "-35 to -30 Loading 20240101_014500\n",
      "-35 to -30 Loading 20240101_020000\n",
      "-35 to -30 Loading 20240101_021500\n",
      "-35 to -30 Loading 20240101_023000\n",
      "-35 to -30 Loading 20240101_024500\n",
      "-35 to -30 Loading 20240101_030000\n",
      "-35 to -30 Loading 20240101_031500\n",
      "-35 to -30 Loading 20240101_033000\n",
      "-35 to -30 Loading 20240101_034500\n",
      "-35 to -30 Loading 20240101_040000\n",
      "-35 to -30 Loading 20240101_041500\n",
      "-35 to -30 Loading 20240101_043000\n",
      "-35 to -30 Loading 20240101_044500\n",
      "-35 to -30 Loading 20240101_050000\n",
      "-35 to -30 Loading 20240101_051500\n",
      "-35 to -30 Loading 20240101_053000\n",
      "-35 to -30 Loading 20240101_054500\n",
      "-35 to -30 Loading 20240101_060000\n",
      "-35 to -30 Loading 20240101_061500\n",
      "-35 to -30 Loading 20240101_063000\n",
      "-35 to -30 Loading 20240101_064500\n",
      "-35 to -30 Loading 20240101_070000\n",
      "-35 to -30 Loading 20240101_071500\n",
      "-35 to -30 Loading 20240101_073000\n",
      "-35 to -30 Loading 20240101_074500\n",
      "-35 to -30 Loading 20240101_080000\n",
      "-35 to -30 Loading 20240101_081500\n",
      "-35 to -30 Loading 20240101_083000\n",
      "-35 to -30 Loading 20240101_084500\n",
      "-35 to -30 Loading 20240101_090000\n",
      "-35 to -30 Loading 20240101_091500\n",
      "-35 to -30 Loading 20240101_093000\n",
      "-35 to -30 Loading 20240101_094500\n",
      "-35 to -30 Loading 20240101_100000\n",
      "-35 to -30 Loading 20240101_101500\n",
      "-35 to -30 Loading 20240101_103000\n",
      "-35 to -30 Loading 20240101_104500\n",
      "-35 to -30 Loading 20240101_110000\n",
      "-35 to -30 Loading 20240101_111500\n",
      "-35 to -30 Loading 20240101_113000\n",
      "-35 to -30 Loading 20240101_114500\n",
      "-35 to -30 Loading 20240101_120000\n",
      "-35 to -30 Loading 20240101_121500\n",
      "-35 to -30 Loading 20240101_123000\n",
      "-35 to -30 Loading 20240101_124500\n",
      "-35 to -30 Loading 20240101_130000\n",
      "-35 to -30 Loading 20240101_131500\n",
      "-35 to -30 Loading 20240101_133000\n",
      "-35 to -30 Loading 20240101_134500\n",
      "-35 to -30 Loading 20240101_140000\n",
      "-35 to -30 Loading 20240101_141500\n",
      "-35 to -30 Loading 20240101_143000\n",
      "-35 to -30 Loading 20240101_144500\n",
      "-35 to -30 Loading 20240101_150000\n",
      "-35 to -30 Loading 20240101_151500\n",
      "-35 to -30 Loading 20240101_153000\n",
      "-35 to -30 Loading 20240101_154500\n",
      "-35 to -30 Loading 20240101_160000\n",
      "-35 to -30 Loading 20240101_161500\n",
      "-35 to -30 Loading 20240101_163000\n",
      "-35 to -30 Loading 20240101_164500\n",
      "-35 to -30 Loading 20240101_170000\n",
      "-35 to -30 Loading 20240101_171500\n",
      "-35 to -30 Loading 20240101_173000\n",
      "-35 to -30 Loading 20240101_174500\n",
      "-35 to -30 Loading 20240101_180000\n",
      "-35 to -30 Loading 20240101_181500\n",
      "-35 to -30 Loading 20240101_183000\n",
      "-35 to -30 Loading 20240101_184500\n",
      "-35 to -30 Loading 20240101_190000\n",
      "-35 to -30 Loading 20240101_191500\n",
      "-35 to -30 Loading 20240101_193000\n",
      "-35 to -30 Loading 20240101_194500\n",
      "-35 to -30 Loading 20240101_200000\n",
      "-35 to -30 Loading 20240101_201500\n",
      "-35 to -30 Loading 20240101_203000\n",
      "-35 to -30 Loading 20240101_204500\n",
      "-35 to -30 Loading 20240101_210000\n",
      "-35 to -30 Loading 20240101_211500\n",
      "-35 to -30 Loading 20240101_213000\n",
      "-35 to -30 Loading 20240101_214500\n",
      "-35 to -30 Loading 20240101_220000\n",
      "-35 to -30 Loading 20240101_221500\n",
      "-35 to -30 Loading 20240101_223000\n",
      "-35 to -30 Loading 20240101_224500\n",
      "-35 to -30 Loading 20240101_230000\n",
      "-35 to -30 Loading 20240101_231500\n",
      "-35 to -30 Loading 20240101_233000\n",
      "-35 to -30 Loading 20240101_234500\n",
      "-35 to -30 Loading 20240102_000000\n",
      "Writing to  /cluster/work/climate/dnikolo/Cloud_analysis/np/20240101.0000_20240102.0000/Agg_03_T_35_30.parquet\n"
     ]
    }
   ],
   "source": [
    "config = read_config(\"/cluster/work/climate/dnikolo/n2o/Glaciation_time_estimator/configs/config_testing_2024.yaml\")\n",
    "tracking_fps = generate_tracking_filenames(config)\n",
    "with Manager() as manager:\n",
    "    cloud_dict = manager.dict()\n",
    "    # TODO: Paralelize here\n",
    "    part_analize_single_pole = partial(\n",
    "        analize_single_pole, cloud_dict=cloud_dict, tracking_fps=tracking_fps, config=config)\n",
    "    part_analize_single_pole(\"np\")\n",
    "    # with NestablePool(2) as pool:\n",
    "    #     pool.map(part_analize_single_pole, config['pole_folders'])\n",
    "    #     pool.close()\n",
    "\n",
    "# def analyse_tracked_clouds(config):\n",
    "#     tracking_fps = generate_tracking_filenames(config)\n",
    "#     with Manager() as manager:\n",
    "#         cloud_dict = manager.dict()\n",
    "#         # TODO: Paralelize here\n",
    "#         part_analize_single_pole = partial(\n",
    "#             analize_single_pole, cloud_dict=cloud_dict, tracking_fps=tracking_fps, config=config)\n",
    "#         with NestablePool(2) as pool:\n",
    "#             pool.map(part_analize_single_pole, config['pole_folders'])\n",
    "#             pool.close()\n",
    "#             pool.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flex_trkr_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
