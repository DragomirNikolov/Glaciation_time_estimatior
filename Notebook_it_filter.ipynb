{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'flex_trkr_2 (Python 3.11.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import time\n",
    "from Helper_fun import time_intersection, generate_temp_range\n",
    "import os\n",
    "import pyproj\n",
    "\n",
    "from pyresample.geometry import SwathDefinition\n",
    "import pyresample.kd_tree as kd_tree\n",
    "from pyresample import get_area_def\n",
    "\n",
    "# ==================================================\n",
    "# Create a merged file that includes the cph field\n",
    "# ==================================================\n",
    "\n",
    "PyFLEXTRKR_LIB_DIR = os.environ['PyFLEXTRKR_LIB_DIR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Lat/LonRESAMPLING##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'flex_trkr_2 (Python 3.11.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class Output_file:\n",
    "    def __init__(self, file_path):\n",
    "        # Create a new NetCDF file\n",
    "        print(file_path)\n",
    "        try:\n",
    "            if os.path.exists(file_path):\n",
    "                # os.chmod(file_path, 0o666)\n",
    "                print(\"File exists\")\n",
    "                self.dataset = nc.Dataset(file_path, 'w', format='NETCDF4')\n",
    "                self.SwathDef=None\n",
    "            else:\n",
    "                print(\"File not found:\", file_path)\n",
    "        except PermissionError:\n",
    "            print(\n",
    "                f\"Permission denied: You don't have the necessary permissions to change the permissions of this file: {file_path}\")\n",
    "            self.dataset = None\n",
    "\n",
    "    def create_dim(self, size_x: int, size_y: int, size_t: int):\n",
    "        try:\n",
    "            # self.dataset.set_fill_off()\n",
    "            self.dataset.createDimension(\"lon\", size_x)\n",
    "            self.dataset.createDimension(\"lat\", size_y)\n",
    "            self.dataset.createDimension('time', size_t)\n",
    "            self.dataset.createDimension('object_num', 2)\n",
    "        except Exception as e:\n",
    "            self.dataset.close()\n",
    "            print(e)\n",
    "\n",
    "    def create_var_t(self, dates, time_units, calendar='gregorian'):\n",
    "        try:\n",
    "            new_time = self.dataset.createVariable('time', 'd', ('time',))\n",
    "            new_time.units = time_units\n",
    "            new_time.calendar = calendar\n",
    "            new_time[:] = nc.date2num(\n",
    "                dates, units=time_units, calendar=calendar)\n",
    "        except Exception as e:\n",
    "            self.dataset.close()\n",
    "            print(e)\n",
    "\n",
    "    def create_var_xy(self, lons, lats):\n",
    "        try:\n",
    "            x_var = self.dataset.createVariable(\n",
    "                'lon', 'd', ('lon', 'lat'), fill_value=np.nan)\n",
    "            # Set x variable attributes\n",
    "            x_var.long_name = \"longitude\"\n",
    "            x_var.standard_name = \"longitude\"\n",
    "            x_var.units = \"degrees_east\"\n",
    "            # Set x variable\n",
    "            print(lons)\n",
    "            x_var[:] = lons\n",
    "\n",
    "            y_var = self.dataset.createVariable(\n",
    "                'lat', 'd', ('lon', 'lat'), fill_value=np.nan)\n",
    "            # Set y variable attributes\n",
    "            y_var.long_name = \"latitude\"\n",
    "            y_var.standard_name = \"latitude\"\n",
    "            y_var.units = \"degrees_north\"\n",
    "            # Set y variable\n",
    "            y_var[:] = lats  # y[y_limited_ind_bug]*10*180/np.pi\n",
    "        except Exception as e:\n",
    "            self.dataset.close()\n",
    "            print(e)\n",
    "\n",
    "    def create_track_variable(self, var_name, var_field):\n",
    "        try:\n",
    "            if var_name == 'cph':\n",
    "                cph_var = self.dataset.createVariable(\n",
    "                    'cph', 'i2', ('time', 'lat', 'lon'), fill_value=-1)\n",
    "                # Copy variable attributes\n",
    "                cph_var.cell_methods = \"time: point\"\n",
    "                cph_var.flag_meanings = \"clear liquid ice\"\n",
    "                cph_var.flag_values = '0s, 1s, 2s'\n",
    "                cph_var.missing_value = -1\n",
    "                cph_var.grid_mapping = \"lonlat\"\n",
    "                cph_var.units = \"1\"\n",
    "                cph_var.long_name = \"Cloud Thermodynamic Phase\"\n",
    "                cph_var.standard_name = \"thermodynamic_phase_of_cloud_water_particles_at_cloud_top\"\n",
    "                # For time-dependent variables, use the ith timestep -(cloud_mask.mask[count,:,:]-1)*50\n",
    "                cph_var[:] = var_field\n",
    "            else:\n",
    "                raise NotImplementedError(\n",
    "                    \"Program still doesnt work for non-cph variables\")\n",
    "        except Exception as e:\n",
    "            self.dataset.close()\n",
    "            print(e)\n",
    "\n",
    "    def generate_lat_lon_prj(self):\n",
    "        sat_data = self.dataset\n",
    "        self.x = sat_data['x'][:]\n",
    "        self.y = sat_data['y'][:]\n",
    "        # Satellite height\n",
    "\n",
    "        # +6378137\n",
    "        sat_h = sat_data.variables['projection'].perspective_point_height\n",
    "\n",
    "        # Satellite longitude\n",
    "        sat_lon = sat_data.variables['projection'].longitude_of_projection_origin\n",
    "\n",
    "        # Satellite sweep\n",
    "        sat_sweep = sat_data.variables['projection'].sweep_angle_axis\n",
    "\n",
    "        # The projection x and y coordinates equals\n",
    "        # the scanning angle (in radians) multiplied by the satellite height (http://proj4.org/projections/geos.html)\n",
    "\n",
    "        X = self.x.data * sat_h\n",
    "        Y = self.y.data * sat_h\n",
    "        XX, YY = np.meshgrid(X, Y)\n",
    "        p = pyproj.Proj(proj='geos', h=sat_h, lon_0=sat_lon, sweep=sat_sweep)\n",
    "        # print(f\"{p.definition_string()}\\n{p.to_proj4()}\")\n",
    "        # ,errcheck=True) #radians=True\n",
    "        lon_mat, lat_mat = p(XX, YY, inverse=True)\n",
    "        lon_mat[np.isinf(lon_mat)] = np.nan\n",
    "        lat_mat[np.isinf(lat_mat)] = np.nan\n",
    "        self.bounds = [np.nanmin(lon_mat.astype(np.float64)), np.nanmax(lon_mat.astype(\n",
    "                    np.float64)), np.nanmin(lat_mat.astype(np.float64)), np.nanmax(lat_mat.astype(np.float64))]\n",
    "        Proj4Args = '+proj=eqc +lat_ts=0 +lat_0=0 +lon_0=0 +x_0=0 +y_0=0 +a=6378.137 +b=6378.137 +units=km'\n",
    "        Prj = pyproj.Proj(Proj4Args)\n",
    "        AreaID = 'cyl'\n",
    "        AreaName = 'cyl'\n",
    "        ProjID = 'cyl'\n",
    "        # print(np.nanmin(lon_mat.astype(np.float64)),np.nanmin(lat_mat.astype(np.float64)))\n",
    "        ny, nx = lon_mat.shape\n",
    "        SW = Prj(self.bounds[0], self.bounds[2])\n",
    "        NW = Prj(self.bounds[1], self.bounds[3])\n",
    "        area_extent = [SW[0], SW[1], NW[0], NW[1]]\n",
    "        # print(area_extent)\n",
    "\n",
    "        self.AreaDef = get_area_def(\n",
    "            AreaID, AreaName, ProjID, Proj4Args, nx, ny, area_extent)\n",
    "        self.SwathDef = SwathDefinition(lons=lon_mat, lats=lat_mat)\n",
    "\n",
    "        self.generate_new_coordinates()\n",
    "        \n",
    "    def generate_new_coordinates(self):\n",
    "        self.new_cord_lon = np.linspace(\n",
    "            self.bounds[0], self.bounds[1], self.x.shape[0])\n",
    "        self.new_cord_lat = np.linspace(\n",
    "            self.bounds[2], self.bounds[3], self.y.shape[0])\n",
    "        \n",
    "    def remap_data(self, var_name, var_field):\n",
    "        sat_data = self.dataset\n",
    "        # Satellite height\n",
    "        if self.SwathDef == None:\n",
    "            self.generate_lat_lon_prj()\n",
    "        outpput_field=np.empty(var_field.shape)\n",
    "        if 'time' in sat_data[var_name].dimentions():\n",
    "            n_timesteps = len(sat_data.dimensions['time'])\n",
    "            \n",
    "            for time_ind in range(n_timesteps):\n",
    "                field_at_timestep = var_field[time_ind, :, :]\n",
    "\n",
    "                outpput_field[time_ind,:,:] = kd_tree.resample_gauss(self.SwathDef, field_at_timestep, self.AreaDef, radius_of_influence=6000,\n",
    "                                              fill_value=-1, epsilon=3)  # reduce_data=True\n",
    "\n",
    "    def close(self):\n",
    "        self.dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'flex_trkr_2 (Python 3.11.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# Filtering and formatting data\n",
    "# ==================================================\n",
    "\n",
    "\n",
    "def filter_data(ctt, cph, min_temp, max_temp):\n",
    "    # Filter by temperature range -38C<T<0C\n",
    "    ctt = np.ma.masked_where((ctt < 273.15 + min_temp)\n",
    "                             | (ctt > 273.15 + max_temp), ctt)\n",
    "    # Create a combined mask that only has entries at positions within temp range and valid phase\n",
    "    cph_filtered = cph.copy()\n",
    "    cph_filtered.mask = ctt.mask | cph.mask\n",
    "\n",
    "    return cph_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'flex_trkr_2 (Python 3.11.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Set up timer\n",
    "start_time = time.time()\n",
    "\n",
    "# ==================================================\n",
    "# Open and load cloud top temp and cloud top phase data\n",
    "# ==================================================\n",
    "\n",
    "print(\"Loading data\")\n",
    "cph_fp = PyFLEXTRKR_LIB_DIR+f'/TEST/cph.CPP.nc.nc'\n",
    "tmp_fp = PyFLEXTRKR_LIB_DIR+f'/TEST/ctt.nc.nc'\n",
    "cph_data = nc.Dataset(cph_fp)  # cloud_phase_file\n",
    "tmp_data = nc.Dataset(tmp_fp)  # cloud_phase_file\n",
    "print(f\"Data loaded. Elapsed time: {time.time()-start_time}\")\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# ==================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'flex_trkr_2 (Python 3.11.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# Load axices\n",
    "# ==================================================\n",
    "\n",
    "print(f\"Setting up dimentions\")\n",
    "\n",
    "# Space dimentions\n",
    "# ==================================================\n",
    "x = tmp_data['x'][:]\n",
    "y = tmp_data['y'][:]\n",
    "\n",
    "# Limit data to a region and time period\n",
    "# Limit between -35 and -75 degree lat\n",
    "y_limited_ind_bug=np.arange(len(y))\n",
    "# y_limited_ind_bug = np.where((y < -0.061) & (y > -0.1396))[0]\n",
    "y_limited_ind = tuple(y_limited_ind_bug)\n",
    "\n",
    "# Generate lat and lon matrices\n",
    "# lon_mat = np.ones((len(y_limited_ind), len(x)))*(x.T * 10 * 180 / np.pi)\n",
    "# lat_mat = np.ones((len(y_limited_ind), len(x))) * \\\n",
    "#     (y[y_limited_ind_bug]*10*180/np.pi)[:, None]\n",
    "\n",
    "# Time dimension\n",
    "# ==================================================\n",
    "\n",
    "# Get time intersection\n",
    "time_ind_ctt, time_ind_cph = time_intersection(\n",
    "    tmp_data['time'], cph_data['time'])\n",
    "\n",
    "# Extract time variable for later use\n",
    "# assuming the time variable is named 'time'\n",
    "time_var = cph_data.variables['time']\n",
    "time_units = time_var.units\n",
    "calendar = time_var.calendar if hasattr(time_var, 'calendar') else 'standard'\n",
    "\n",
    "# Convert time steps to dates using netCDF num2date\n",
    "dates = nc.num2date(time_var[:], units=time_units, calendar=\"gregorian\")\n",
    "\n",
    "print(f\"Dimentions set. Elapsed time: {time.time()-start_time}\")\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# ==================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'flex_trkr_2 (Python 3.11.6)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# ==================================================\n",
    "# Filter data and generate new files\n",
    "# ==================================================\n",
    "\n",
    "print(\"Loading copies of data\")\n",
    "# Get reduced data arrays ctt and cph\n",
    "ctt = tmp_data['ctt'][time_ind_ctt, y_limited_ind, :]\n",
    "cph = cph_data['cph'][time_ind_cph, y_limited_ind, :]\n",
    "# [2,5,10,15,38]\n",
    "t_deltas = [38]  # [2,5,10,15,38]\n",
    "temp_bounds = generate_temp_range(t_deltas)\n",
    "print(temp_bounds)\n",
    "\n",
    "for i in range(temp_bounds[0].shape[0]):\n",
    "    min_temp = temp_bounds[0][i]\n",
    "    max_temp = temp_bounds[1][i]\n",
    "    cph_filtered = filter_data(ctt, cph, min_temp, max_temp)\n",
    "    print(f\"Generating new merged file: T={min_temp}:{max_temp}\")\n",
    "\n",
    "    output_file_generator_remap(\n",
    "        cph_filtered.filled(fill_value=0), y_limited_ind_bug, dates, min_temp, max_temp, x, y)\n",
    "    print(\n",
    "        f\"New merged file generated and saved. Elapsed time {time.time()-start_time}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flex_trkr_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
