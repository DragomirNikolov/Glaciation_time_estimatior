{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set enviromnetal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PyFLEXTRKR_LIB_DIR=/home/dragomir/University_Stuff/Thesis/Python_work\n"
     ]
    }
   ],
   "source": [
    "%env PyFLEXTRKR_LIB_DIR=/home/dragomir/University_Stuff/Thesis/Python_work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required functions and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import time\n",
    "from Helper_fun import time_intersection, generate_temp_range\n",
    "import os\n",
    "import pyproj\n",
    "\n",
    "from pyresample.geometry import SwathDefinition\n",
    "import pyresample.kd_tree as kd_tree\n",
    "from pyresample import get_area_def\n",
    "\n",
    "# ==================================================\n",
    "# Create a merged file that includes the cph field\n",
    "# ==================================================\n",
    "\n",
    "PyFLEXTRKR_LIB_DIR = os.environ['PyFLEXTRKR_LIB_DIR']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define output file class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Output_file:\n",
    "    def __init__(self, file_path):\n",
    "        # Create a new NetCDF file\n",
    "        print(file_path)\n",
    "        try:\n",
    "            if os.path.exists(file_path):\n",
    "                # os.chmod(file_path, 0o666)\n",
    "                print(\"File exists\")\n",
    "                self.dataset = nc.Dataset(file_path, 'w', format='NETCDF4')\n",
    "                self.SwathDef = None\n",
    "            else:\n",
    "                print(\"File not found:\", file_path)\n",
    "        except PermissionError:\n",
    "            print(\n",
    "                f\"Permission denied: You don't have the necessary permissions to change the permissions of this file: {file_path}\")\n",
    "            self.dataset = None\n",
    "\n",
    "    def create_dim(self, size_x: int, size_y: int, size_t: int):\n",
    "        try:\n",
    "            # self.dataset.set_fill_off()\n",
    "            self.dataset.createDimension(\"lon\", size_x)\n",
    "            self.dataset.createDimension(\"lat\", size_y)\n",
    "            self.dataset.createDimension('time', size_t)\n",
    "            self.dataset.createDimension('object_num', 2)\n",
    "        except Exception as e:\n",
    "            self.dataset.close()\n",
    "            print(f\"create_dim: {e}\")\n",
    "\n",
    "    def create_var_t(self, dates, time_units, calendar='gregorian'):\n",
    "        try:\n",
    "            new_time = self.dataset.createVariable('time', 'd', ('time',))\n",
    "            new_time.units = time_units\n",
    "            new_time.calendar = calendar\n",
    "            new_time[:] = nc.date2num(\n",
    "                dates, units=time_units, calendar=calendar)\n",
    "        except Exception as e:\n",
    "            self.dataset.close()\n",
    "            print(f\"create_var_t:\\n{e}\")\n",
    "\n",
    "    def create_var_xy(self, lons, lats):\n",
    "        try:\n",
    "            x_var = self.dataset.createVariable(\n",
    "                'lon', 'd', ('lon',), fill_value=np.nan)\n",
    "            # Set x variable attributes\n",
    "            x_var.long_name = \"longitude\"\n",
    "            x_var.standard_name = \"longitude\"\n",
    "            x_var.units = \"degrees_east\"\n",
    "            # Set x variable\n",
    "            print(lons)\n",
    "            x_var[:] = lons\n",
    "\n",
    "            y_var = self.dataset.createVariable(\n",
    "                'lat', 'd', ('lat',), fill_value=np.nan)\n",
    "            # Set y variable attributes\n",
    "            y_var.long_name = \"latitude\"\n",
    "            y_var.standard_name = \"latitude\"\n",
    "            y_var.units = \"degrees_north\"\n",
    "            # Set y variable\n",
    "            y_var[:] = lats  # y[lat_limited_ind]*10*180/np.pi\n",
    "        except Exception as e:\n",
    "            self.dataset.close()\n",
    "            print(f\"create_var_xy:\\n{e}\")\n",
    "\n",
    "    def create_track_variable(self, var_name, var_field):\n",
    "        try:\n",
    "            if var_name == 'cph':\n",
    "                cph_var = self.dataset.createVariable(\n",
    "                    'cph', 'i2', ('time', 'lat', 'lon'), fill_value=-1)\n",
    "                # Copy variable attributes\n",
    "                cph_var.cell_methods = \"time: point\"\n",
    "                cph_var.flag_meanings = \"clear liquid ice\"\n",
    "                cph_var.flag_values = '0s, 1s, 2s'\n",
    "                cph_var.missing_value = -1\n",
    "                cph_var.grid_mapping = \"projection\"\n",
    "                cph_var.units = \"1\"\n",
    "                cph_var.long_name = \"Cloud Thermodynamic Phase\"\n",
    "                cph_var.standard_name = \"thermodynamic_phase_of_cloud_water_particles_at_cloud_top\"\n",
    "                # For time-dependent variables, use the ith timestep -(cloud_mask.mask[count,:,:]-1)*50\n",
    "                cph_var[:] = var_field\n",
    "            else:\n",
    "                raise NotImplementedError(\n",
    "                    \"Program still doesnt work for non-cph variables\")\n",
    "        except Exception as e:\n",
    "            self.dataset.close()\n",
    "            print(f\"create_track_variable:\\n{e}\")\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        self.dataset.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projection_transformer():\n",
    "    def generate_lat_lon_prj(self,sat_data):\n",
    "        self.x = sat_data['x'][:]\n",
    "        self.y = sat_data['y'][:]\n",
    "        # Satellite height\n",
    "\n",
    "        # +6378137\n",
    "        sat_h = sat_data.variables['projection'].perspective_point_height\n",
    "\n",
    "        # Satellite longitude\n",
    "        sat_lon = sat_data.variables['projection'].longitude_of_projection_origin\n",
    "\n",
    "        # Satellite sweep\n",
    "        sat_sweep = sat_data.variables['projection'].sweep_angle_axis\n",
    "\n",
    "        # The projection x and y coordinates equals\n",
    "        # the scanning angle (in radians) multiplied by the satellite height (http://proj4.org/projections/geos.html)\n",
    "\n",
    "        X = self.x.data * sat_h\n",
    "        Y = self.y.data * sat_h\n",
    "        XX, YY = np.meshgrid(X, Y)\n",
    "        p = pyproj.Proj(proj='geos', h=sat_h,\n",
    "                        lon_0=sat_lon, sweep=sat_sweep)\n",
    "        # print(f\"{p.definition_string()}\\n{p.to_proj4()}\")\n",
    "        # ,errcheck=True) #radians=True\n",
    "        # Generates lat and longitude matrixes taht indicate the corresponding latitude and longitude of each data within the field\n",
    "        lon_mat, lat_mat = p(XX, YY, inverse=True)\n",
    "        lon_mat[np.isinf(lon_mat)] = np.nan\n",
    "        lat_mat[np.isinf(lat_mat)] = np.nan\n",
    "        # Generate variables needed for the later reshaping of the data\n",
    "        self.bounds = [np.nanmin(lon_mat.astype(np.float64)), np.nanmax(lon_mat.astype(\n",
    "            np.float64)), np.nanmin(lat_mat.astype(np.float64)), np.nanmax(lat_mat.astype(np.float64))]\n",
    "        print(f\"Bounds = {self.bounds}\")\n",
    "        Proj4Args = '+proj=eqc +lat_ts=0 +lat_0=0 +lon_0=0 +x_0=0 +y_0=0 +a=6378.137 +b=6378.137 +units=km'\n",
    "        Prj = pyproj.Proj(Proj4Args)\n",
    "        AreaID = 'cyl'\n",
    "        AreaName = 'cyl'\n",
    "        ProjID = 'cyl'\n",
    "        # print(np.nanmin(lon_mat.astype(np.float64)),np.nanmin(lat_mat.astype(np.float64)))\n",
    "        ny, nx = lon_mat.shape\n",
    "        # Get the projected poisions of the mst South West and North ast points: Usually outputs sth in the range 5-15\n",
    "        # I have no idea how it works acually but it works so I wont question it\n",
    "        SW = Prj(self.bounds[0], self.bounds[2])\n",
    "        NW = Prj(self.bounds[1], self.bounds[3])\n",
    "        area_extent = [SW[0], SW[1], NW[0], NW[1]]\n",
    "        # print(area_extent)\n",
    "        # The transformation in remap_data transforms th data from SwathDef to AreaDef\n",
    "        self.AreaDef = get_area_def(\n",
    "            AreaID, AreaName, ProjID, Proj4Args, nx, ny, area_extent)\n",
    "        self.SwathDef = SwathDefinition(lons=lon_mat, lats=lat_mat)\n",
    "\n",
    "        self.generate_new_coordinates()\n",
    "\n",
    "    def generate_new_coordinates(self):\n",
    "        self.new_cord_lon = np.linspace(\n",
    "            self.bounds[0], self.bounds[1], self.x.shape[0])\n",
    "        self.new_cord_lat = np.linspace(\n",
    "            self.bounds[2], self.bounds[3], self.y.shape[0])\n",
    "\n",
    "    def remap_data(self, var_field):\n",
    "        # Satellite height\n",
    "        if self.SwathDef == None:\n",
    "            self.generate_lat_lon_prj()\n",
    "        output_field = np.empty(var_field.shape)\n",
    "        if len(var_field.shape)==3:\n",
    "            output_field = kd_tree.resample_nearest(self.SwathDef, var_field.transpose(1,2,0), self.AreaDef, radius_of_influence=6000,\n",
    "                                                                    fill_value=-1, epsilon=3)  # reduce_data=True\n",
    "            output_field=output_field.transpose(2,0,1)\n",
    "            return output_field\n",
    "        else:\n",
    "            raise NotImplementedError(\"2D var field remapping not yet added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output file generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_file_generator_remap (cph_data, var_field, lat_limited_ind, lon_limited_ind, dates, time_ind, time_units,calendar,  min_temp, max_temp, Transformer):\n",
    "    PyFLEXTRKR_LIB_DIR = os.environ['PyFLEXTRKR_LIB_DIR']\n",
    "    date = dates[0]\n",
    "    new_file_name = PyFLEXTRKR_LIB_DIR + \\\n",
    "        f\"/TEST/example_preprocessing/CTT-it-{round(abs(min_temp))}-{round(abs(max_temp))}-{date.day:02d}-{date.month:02d}-{date.year}_{date.hour:02d}:{date.minute:02d}:{date.second:02d}.nc\"\n",
    "    test=nc.Dataset(new_file_name, 'w', format='NETCDF4')\n",
    "    test.close()\n",
    "    # Create a new NetCDF file,\n",
    "    new_dataset = Output_file(new_file_name)\n",
    "\n",
    "    # Create dimentions,\n",
    "    new_dataset.create_dim(len(lon_limited_ind), len(lat_limited_ind), len(time_ind)),\n",
    "    new_dataset.create_var_t(dates[time_ind], time_units, calendar),\n",
    "    new_dataset.create_var_xy(Transformer.new_cord_lon[lon_limited_ind], Transformer.new_cord_lat[lat_limited_ind])\n",
    "    # Create track variable\n",
    "    new_dataset.create_track_variable('cph', var_field)\n",
    "    # Copy variables from the original file, except the the ones that are manually set\n",
    "    for var_name, var in cph_data.variables.items():\n",
    "        if not (var_name in ['cph', 'x', 'y', 'time']):\n",
    "            print(f\"#################################### \\n It activates for {var_name}\\n###########################\")\n",
    "            new_var = new_dataset.dataset.createVariable(\n",
    "                var_name, var.dtype, var.dimensions)\n",
    "            # Copy variable attributes\n",
    "            new_var.setncatts({k: var.getncattr(k) for k in var.ncattrs()})\n",
    "            new_var[:] = var[time_ind] if 'time' in var.dimensions else var[:]\n",
    "\n",
    "    # Close the new file\n",
    "    new_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Filtering and formatting data\n",
    "# ==================================================\n",
    "\n",
    "\n",
    "def filter_data(ctt, cph, min_temp, max_temp):\n",
    "    # Filter by temperature range -38C<T<0C\n",
    "    ctt = np.ma.masked_where((ctt < 273.15 + min_temp)\n",
    "                             | (ctt > 273.15 + max_temp), ctt)\n",
    "    # Create a combined mask that only has entries at positions within temp range and valid phase\n",
    "    cph_filtered = cph.copy()\n",
    "    cph_filtered.mask = ctt.mask | cph.mask\n",
    "\n",
    "    return cph_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Data loaded. Elapsed time: 0.001222848892211914\n"
     ]
    }
   ],
   "source": [
    "# Set up timer\n",
    "start_time = time.time()\n",
    "\n",
    "# ==================================================\n",
    "# Open and load cloud top temp and cloud top phase data\n",
    "# ==================================================\n",
    "\n",
    "print(\"Loading data\")\n",
    "cph_fp = PyFLEXTRKR_LIB_DIR+f'/TEST/cph.CPP.nc.nc'\n",
    "tmp_fp = PyFLEXTRKR_LIB_DIR+f'/TEST/ctt.nc.nc'\n",
    "cph_data = nc.Dataset(cph_fp)  # cloud_phase_file\n",
    "tmp_data = nc.Dataset(tmp_fp)  # cloud_phase_file\n",
    "print(f\"Data loaded. Elapsed time: {time.time()-start_time}\")\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# ==================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up dimentions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29697/4141777414.py:9: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = tmp_data['x'][:]\n",
      "/tmp/ipykernel_29697/4141777414.py:10: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = tmp_data['y'][:]\n",
      "/tmp/ipykernel_29697/1317374832.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self.x = sat_data['x'][:]\n",
      "/tmp/ipykernel_29697/1317374832.py:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self.y = sat_data['y'][:]\n",
      "/tmp/ipykernel_29697/1317374832.py:14: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  sat_sweep = sat_data.variables['projection'].sweep_angle_axis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounds = [-81.26781815747441, 81.26032881685039, -81.18369218549527, 80.89292064320712]\n",
      "Dimentions set. Elapsed time: 2.360666036605835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29697/4141777414.py:34: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  time_units = time_var.units\n",
      "/tmp/ipykernel_29697/4141777414.py:35: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  calendar = time_var.calendar if hasattr(time_var, 'calendar') else 'standard'\n",
      "/tmp/ipykernel_29697/4141777414.py:38: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dates = nc.num2date(time_var[:], units=time_units, calendar=\"gregorian\")\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# Load axices\n",
    "# ==================================================\n",
    "\n",
    "print(f\"Setting up dimentions\")\n",
    "\n",
    "# Space dimentions\n",
    "# ==================================================\n",
    "x = tmp_data['x'][:]\n",
    "y = tmp_data['y'][:]\n",
    "\n",
    "Transformer=Projection_transformer()\n",
    "Transformer.generate_lat_lon_prj(cph_data)\n",
    "\n",
    "# Limit data to a time period\n",
    "\n",
    "\n",
    "\n",
    "# Generate lat and lon matrices\n",
    "# lon_mat = np.ones((len(lat_limited_ind), len(x)))*(x.T * 10 * 180 / np.pi)\n",
    "# lat_mat = np.ones((len(lat_limited_ind), len(x))) * \\\n",
    "#     (y[lat_limited_ind]*10*180/np.pi)[:, None]\n",
    "\n",
    "# Time dimension\n",
    "# ==================================================\n",
    "\n",
    "# Get time intersection\n",
    "time_ind_ctt, time_ind_cph = time_intersection(\n",
    "    tmp_data['time'], cph_data['time'])\n",
    "\n",
    "# Extract time variable for later use\n",
    "# assuming the time variable is named 'time'\n",
    "time_var = cph_data.variables['time']\n",
    "time_units = time_var.units\n",
    "calendar = time_var.calendar if hasattr(time_var, 'calendar') else 'standard'\n",
    "\n",
    "# Convert time steps to dates using netCDF num2date\n",
    "dates = nc.num2date(time_var[:], units=time_units, calendar=\"gregorian\")\n",
    "\n",
    "print(f\"Dimentions set. Elapsed time: {time.time()-start_time}\")\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# ==================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Transform initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading copies of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29697/2553055058.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  ctt = tmp_data['ctt'][time_ind_ctt, :, :]\n",
      "/tmp/ipykernel_29697/2553055058.py:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  cph = cph_data['cph'][time_ind_cph, :, :]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb Cell 16\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# [2,5,10,15,38]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ctt\u001b[39m=\u001b[39mTransformer\u001b[39m.\u001b[39mremap_data(ctt)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m cph\u001b[39m=\u001b[39mTransformer\u001b[39m.\u001b[39;49mremap_data(cph)\n",
      "\u001b[1;32m/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb Cell 16\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X21sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m output_field \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(var_field\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X21sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(var_field\u001b[39m.\u001b[39mshape)\u001b[39m==\u001b[39m\u001b[39m3\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X21sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     output_field \u001b[39m=\u001b[39m kd_tree\u001b[39m.\u001b[39;49mresample_nearest(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSwathDef, var_field\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m0\u001b[39;49m), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mAreaDef, radius_of_influence\u001b[39m=\u001b[39;49m\u001b[39m6000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X21sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m                                                             fill_value\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, epsilon\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)  \u001b[39m# reduce_data=True\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X21sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     output_field\u001b[39m=\u001b[39moutput_field\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X21sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m output_field\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyresample/kd_tree.py:107\u001b[0m, in \u001b[0;36mresample_nearest\u001b[0;34m(source_geo_def, data, target_geo_def, radius_of_influence, epsilon, fill_value, reduce_data, nprocs, segments)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresample_nearest\u001b[39m(source_geo_def,\n\u001b[1;32m     65\u001b[0m                      data,\n\u001b[1;32m     66\u001b[0m                      target_geo_def,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m                      nprocs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     72\u001b[0m                      segments\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     73\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Resamples data using kd-tree nearest neighbour approach.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39m        Source data resampled to target geometry\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mreturn\u001b[39;00m _resample(source_geo_def, data, target_geo_def, \u001b[39m'\u001b[39;49m\u001b[39mnn\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    108\u001b[0m                      radius_of_influence, neighbours\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    109\u001b[0m                      epsilon\u001b[39m=\u001b[39;49mepsilon, fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m    110\u001b[0m                      reduce_data\u001b[39m=\u001b[39;49mreduce_data, nprocs\u001b[39m=\u001b[39;49mnprocs, segments\u001b[39m=\u001b[39;49msegments)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyresample/kd_tree.py:261\u001b[0m, in \u001b[0;36m_resample\u001b[0;34m(source_geo_def, data, target_geo_def, resample_type, radius_of_influence, neighbours, epsilon, weight_funcs, fill_value, reduce_data, nprocs, segments, with_uncert)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_resample\u001b[39m(source_geo_def, data, target_geo_def, resample_type,\n\u001b[1;32m    257\u001b[0m               radius_of_influence, neighbours\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, epsilon\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weight_funcs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    258\u001b[0m               fill_value\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, reduce_data\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, nprocs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, segments\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, with_uncert\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    259\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Resamples swath using kd-tree approach.\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     valid_input_index, valid_output_index, index_array, distance_array \u001b[39m=\u001b[39m \\\n\u001b[0;32m--> 261\u001b[0m         get_neighbour_info(source_geo_def,\n\u001b[1;32m    262\u001b[0m                            target_geo_def,\n\u001b[1;32m    263\u001b[0m                            radius_of_influence,\n\u001b[1;32m    264\u001b[0m                            neighbours\u001b[39m=\u001b[39;49mneighbours,\n\u001b[1;32m    265\u001b[0m                            epsilon\u001b[39m=\u001b[39;49mepsilon,\n\u001b[1;32m    266\u001b[0m                            reduce_data\u001b[39m=\u001b[39;49mreduce_data,\n\u001b[1;32m    267\u001b[0m                            nprocs\u001b[39m=\u001b[39;49mnprocs,\n\u001b[1;32m    268\u001b[0m                            segments\u001b[39m=\u001b[39;49msegments)\n\u001b[1;32m    270\u001b[0m     \u001b[39mreturn\u001b[39;00m get_sample_from_neighbour_info(resample_type,\n\u001b[1;32m    271\u001b[0m                                           target_geo_def\u001b[39m.\u001b[39mshape,\n\u001b[1;32m    272\u001b[0m                                           data, valid_input_index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m                                           fill_value\u001b[39m=\u001b[39mfill_value,\n\u001b[1;32m    278\u001b[0m                                           with_uncert\u001b[39m=\u001b[39mwith_uncert)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyresample/kd_tree.py:333\u001b[0m, in \u001b[0;36mget_neighbour_info\u001b[0;34m(source_geo_def, target_geo_def, radius_of_influence, neighbours, epsilon, reduce_data, nprocs, segments)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39m# Create kd-tree\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     resample_kdtree \u001b[39m=\u001b[39m _create_resample_kdtree(source_lons, source_lats,\n\u001b[1;32m    334\u001b[0m                                               valid_input_index,\n\u001b[1;32m    335\u001b[0m                                               nprocs\u001b[39m=\u001b[39;49mnprocs)\n\u001b[1;32m    336\u001b[0m \u001b[39mexcept\u001b[39;00m EmptyResult:\n\u001b[1;32m    337\u001b[0m     \u001b[39m# Handle if all input data is reduced away\u001b[39;00m\n\u001b[1;32m    338\u001b[0m     valid_output_index, index_array, distance_array \u001b[39m=\u001b[39m \\\n\u001b[1;32m    339\u001b[0m         _create_empty_info(source_geo_def, target_geo_def, neighbours)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyresample/kd_tree.py:477\u001b[0m, in \u001b[0;36m_create_resample_kdtree\u001b[0;34m(source_lons, source_lats, valid_input_index, nprocs)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    475\u001b[0m     cartesian \u001b[39m=\u001b[39m _spatial_mp\u001b[39m.\u001b[39mCartesian()\n\u001b[0;32m--> 477\u001b[0m input_coords \u001b[39m=\u001b[39m cartesian\u001b[39m.\u001b[39;49mtransform_lonlats(source_lons_valid,\n\u001b[1;32m    478\u001b[0m                                            source_lats_valid)\n\u001b[1;32m    480\u001b[0m \u001b[39mif\u001b[39;00m input_coords\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    481\u001b[0m     \u001b[39mraise\u001b[39;00m EmptyResult(\u001b[39m'\u001b[39m\u001b[39mNo valid data points in input data\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyresample/_spatial_mp.py:163\u001b[0m, in \u001b[0;36mCartesian.transform_lonlats\u001b[0;34m(self, lons, lats)\u001b[0m\n\u001b[1;32m    161\u001b[0m     deg2rad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpi \u001b[39m/\u001b[39m \u001b[39m180\u001b[39m  \u001b[39m# noqa: F841\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     coords[:, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m ne\u001b[39m.\u001b[39mevaluate(\u001b[39m\"\u001b[39m\u001b[39mR*cos(lats*deg2rad)*cos(lons*deg2rad)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 163\u001b[0m     coords[:, \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m ne\u001b[39m.\u001b[39;49mevaluate(\u001b[39m\"\u001b[39;49m\u001b[39mR*cos(lats*deg2rad)*sin(lons*deg2rad)\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    164\u001b[0m     coords[:, \u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m ne\u001b[39m.\u001b[39mevaluate(\u001b[39m\"\u001b[39m\u001b[39mR*sin(lats*deg2rad)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    165\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numexpr/necompiler.py:764\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m _numexpr_last \u001b[39m=\u001b[39m {}\n\u001b[1;32m    762\u001b[0m evaluate_lock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mLock()\n\u001b[0;32m--> 764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(ex, local_dict\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, global_dict\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    765\u001b[0m              out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mK\u001b[39m\u001b[39m'\u001b[39m, casting\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msafe\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    766\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[39m    Evaluate a simple array expression element-wise, using the new iterator.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[39m          * 'unsafe' means any data conversions may be done.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    809\u001b[0m     \u001b[39mglobal\u001b[39;00m _numexpr_last\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Loading copies of data\")\n",
    "# Get reduced data arrays ctt and cph\n",
    "ctt = tmp_data['ctt'][time_ind_ctt, :, :]\n",
    "cph = cph_data['cph'][time_ind_cph, :, :]\n",
    "# [2,5,10,15,38]\n",
    "ctt=Transformer.remap_data(ctt)\n",
    "cph=Transformer.remap_data(cph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limit data to a region between 50 and 70 deg latitude and -60 60 longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 486,  487,  488, ..., 3223, 3224, 3225])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "lat_limited_ind = np.where((Transformer.new_cord_lat>=-70) & (Transformer.new_cord_lat<=-50))[0]\n",
    "lon_limited_ind = np.where((Transformer.new_cord_lon>=-60) & (Transformer.new_cord_lon<=60))[0]\n",
    "lat_limited_ind_bug = tuple(lat_limited_ind)\n",
    "lon_limited_ind_bug = tuple(lon_limited_ind)\n",
    "\n",
    "# Use np.ix_ to create a meshgrid of indices\n",
    "lat_lon_index = np.ix_(lat_limited_ind, lon_limited_ind)\n",
    "\n",
    "# Apply the index\n",
    "ctt = ctt[:, lat_lon_index[0], lat_lon_index[1]]\n",
    "cph = cph[:, lat_lon_index[0], lat_lon_index[1]]\n",
    "lon_limited_ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating new merged file: T=-5:0\n",
      "/home/dragomir/University_Stuff/Thesis/Python_work/TEST/example_preprocessing/CTT-it-5-0-01-02-2004_14:15:00.nc\n",
      "File exists\n",
      "[-81.26781816 -81.22402184 -81.18022552 ...  81.17273617  81.2165325\n",
      "  81.26032882]\n",
      "create_var_xy:\n",
      "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (2740,) and arg 1 with shape (3712,).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: Not a valid ID",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb Cell 19\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mif\u001b[39;00m var_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcph\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     cph_var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mcreateVariable(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mcph\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mi2\u001b[39;49m\u001b[39m'\u001b[39;49m, (\u001b[39m'\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlat\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlon\u001b[39;49m\u001b[39m'\u001b[39;49m), fill_value\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     \u001b[39m# Copy variable attributes\u001b[39;00m\n",
      "File \u001b[0;32mnetCDF4/_netCDF4.pyx:2736\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.createVariable\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnetCDF4/_netCDF4.pyx:3758\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnetCDF4/_netCDF4.pyx:1857\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: Not a valid ID",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m cph_filtered \u001b[39m=\u001b[39m filter_data(ctt, cph, min_temp, max_temp)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenerating new merged file: T=\u001b[39m\u001b[39m{\u001b[39;00mmin_temp\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mmax_temp\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m output_file_generator_remap(cph_data, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     cph_filtered\u001b[39m.\u001b[39;49mfilled(fill_value\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m), lat_limited_ind, lon_limited_ind, dates,time_ind_cph,time_units, calendar, min_temp, max_temp, Transformer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNew merged file generated and saved. Elapsed time \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mstart_time\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m new_dataset\u001b[39m.\u001b[39mcreate_var_xy(Transformer\u001b[39m.\u001b[39mnew_cord_lon, Transformer\u001b[39m.\u001b[39mnew_cord_lat)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Create track variable\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m new_dataset\u001b[39m.\u001b[39;49mcreate_track_variable(\u001b[39m'\u001b[39;49m\u001b[39mcph\u001b[39;49m\u001b[39m'\u001b[39;49m, var_field)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Copy variables from the original file, except the the ones that are manually set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m var_name, var \u001b[39min\u001b[39;00m cph_data\u001b[39m.\u001b[39mvariables\u001b[39m.\u001b[39mitems():\n",
      "\u001b[1;32m/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb Cell 19\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mProgram still doesnt work for non-cph variables\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mclose()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dragomir/University_Stuff/Thesis/Python_work/Glaciation_time_estimatior/Notebook_it_filter.ipynb#X15sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcreate_track_variable:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32mnetCDF4/_netCDF4.pyx:2453\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.close\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnetCDF4/_netCDF4.pyx:2417\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset._close\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnetCDF4/_netCDF4.pyx:1857\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: Not a valid ID"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==================================================\n",
    "# Filter data and generate new files\n",
    "# ==================================================\n",
    "\n",
    "\n",
    "t_deltas = [5,38]  # [2,,10,15,38]\n",
    "temp_bounds = generate_temp_range(t_deltas)\n",
    "\n",
    "for i in range(temp_bounds[0].shape[0]):\n",
    "    min_temp = temp_bounds[0][i]\n",
    "    max_temp = temp_bounds[1][i]\n",
    "    cph_filtered = filter_data(ctt, cph, min_temp, max_temp)\n",
    "    print(f\"Generating new merged file: T={min_temp}:{max_temp}\")\n",
    "\n",
    "    output_file_generator_remap(cph_data, \n",
    "        cph_filtered.filled(fill_value=0), lat_limited_ind, lon_limited_ind, dates,time_ind_cph,time_units, calendar, min_temp, max_temp, Transformer)\n",
    "    print(\n",
    "        f\"New merged file generated and saved. Elapsed time {time.time()-start_time}\")\n",
    "           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
